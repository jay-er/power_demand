import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from lightgbm import LGBMRegressor
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional, Dict, Any
import io
import gspread
from google.oauth2.service_account import Credentials
import os
import json
from functools import partial
import holidays

# ì„±ëŠ¥ ê´€ë ¨ ìƒìˆ˜
APPLY_SHEET_FORMATTING = False  # êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ì„œì‹ ì ìš© ì—¬ë¶€ (ì†ë„ ê°œì„ ì„ ìœ„í•´ ê¸°ë³¸ ë¹„í™œì„±í™”)
QUICK_SHEET_CONNECT = True      # êµ¬ê¸€ì‹œíŠ¸ ì—°ê²° ì‹œ ê²€ì¦ í˜¸ì¶œ ìƒëµí•˜ì—¬ ì´ˆê¸° ë¡œë”© ê°€ì†

# í•™ìŠµ ìºì‹± í•¨ìˆ˜ë“¤
@st.cache_resource(show_spinner=False)
def train_rf_model(X: pd.DataFrame, y: pd.Series, *, n_estimators: int, random_state: int) -> RandomForestRegressor:
    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state, n_jobs=-1)
    model.fit(X, y)
    return model

def tune_rf_model(
    X: pd.DataFrame,
    y: pd.Series,
    *,
    random_state: int,
):
    """ê°„ë‹¨í•œ ì‹œê³„ì—´ CV ê¸°ë°˜ RandomForest íŠœë‹."""
    # ì‹œê³„ì—´ ë¶„í•  (ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ì‹œê°„ ìˆœì„œë¡œ ê°€ì •)
    tscv = TimeSeriesSplit(n_splits=3)
    param_distributions = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 8, 12, 16],
        'min_samples_leaf': [1, 2, 4],
    }
    base = RandomForestRegressor(random_state=random_state, n_jobs=-1)
    search = RandomizedSearchCV(
        estimator=base,
        param_distributions=param_distributions,
        n_iter=6,
        scoring='neg_mean_absolute_error',
        cv=tscv,
        random_state=random_state,
        n_jobs=-1,
        verbose=0,
    )
    search.fit(X, y)
    return search.best_estimator_

def chronological_split(
    X: pd.DataFrame,
    y: pd.Series,
    dates: pd.Series,
    *,
    test_size: float,
):
    """ì‹œê°„ ìˆœì„œ(ì˜¤ë¦„ì°¨ìˆœ)ë¡œ í•™ìŠµ/í‰ê°€ ì„¸íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.

    ë§ˆì§€ë§‰ test_size ë¹„ìœ¨ êµ¬ê°„ì„ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # ì •ë ¬ìš© ì¸ë±ìŠ¤
        sort_idx = dates.sort_values().index
        X_sorted = X.loc[sort_idx]
        y_sorted = y.loc[sort_idx]
        split_idx = int(len(X_sorted) * (1 - test_size))
        split_idx = max(1, min(split_idx, len(X_sorted) - 1))
        return (
            X_sorted.iloc[:split_idx],
            X_sorted.iloc[split_idx:],
            y_sorted.iloc[:split_idx],
            y_sorted.iloc[split_idx:],
        )
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ì „ì²´ë¥¼ í•™ìŠµìœ¼ë¡œ ë°˜í™˜
        return X, X.iloc[0:0], y, y.iloc[0:0]

def align_features_for_model(model, df: pd.DataFrame) -> pd.DataFrame:
    """ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì»¬ëŸ¼ ì§‘í•©(feature_names_in_)ì— ì…ë ¥ì„ ì •ë ¬.
    - í•™ìŠµ ì‹œ ìˆì—ˆë˜ ì»¬ëŸ¼ì´ ì˜ˆì¸¡ ì‹œ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ìƒì„±
    - í•™ìŠµ ì‹œ ì—†ë˜ ì»¬ëŸ¼ì€ ë“œë¡­
    - ì»¬ëŸ¼ ìˆœì„œ ì¼ì¹˜
    """
    try:
        feature_names = list(getattr(model, 'feature_names_in_', []))
        if feature_names:
            for col in feature_names:
                if col not in df.columns:
                    df[col] = 0.0
            # ì—¬ë¶„ ì»¬ëŸ¼ ì œê±° ë° ìˆœì„œ ì •ë ¬
            df = df[feature_names]
    except Exception:
        pass
    return df

@st.cache_resource(show_spinner=False)
def train_lgbm_gas_model(
    X: pd.DataFrame,
    y: pd.Series,
    *,
    monotone_constraints: list,
    n_estimators: int,
    learning_rate: float,
    num_leaves: int,
    min_child_samples: int,
    random_state: int
):
    # ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§Œ ìºì‹œ í‚¤ì— ë°˜ì˜í•˜ë„ë¡ ì¸ì ìœ ì§€
    model = LGBMRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        num_leaves=num_leaves,
        min_child_samples=min_child_samples,
        random_state=random_state,
        n_jobs=-1,
        monotone_constraints=monotone_constraints,
    )
    model.fit(X, y)
    return model

# í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ì–´ì—¬ì•¼ í•¨)
st.set_page_config(
    page_title="ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
    page_icon="âš¡",
    layout="wide"
)

# ì œëª©
st.title("âš¡ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("---")

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'mae_max' not in st.session_state:
    st.session_state.mae_max = None
if 'r2_max' not in st.session_state:
    st.session_state.r2_max = None

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
@st.cache_resource(show_spinner=False)
def setup_google_sheets():
    """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •"""
    try:
        # êµ¬ê¸€ ì‹œíŠ¸ API ìŠ¤ì½”í”„ ì„¤ì •
        scope = [
            'https://spreadsheets.google.com/feeds',
            'https://www.googleapis.com/auth/drive'
        ]
        
        # ë°©ë²• 1: Streamlit secretsì—ì„œ JSON í‚¤ ì½ê¸° (ìš°ì„ ìˆœìœ„)
        try:
            google_credentials_json = st.secrets.get('GOOGLE_CREDENTIALS_JSON')
            if google_credentials_json:
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸(ì˜µì…˜)
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: power-supply@flash-zenith-453703-p6.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì„ í¸ì§‘ìë¡œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
            else:
                st.warning("âš ï¸ Streamlit secretsì—ì„œ GOOGLE_CREDENTIALS_JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ Streamlit secrets ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
        
        # ë°©ë²• 2: ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ì½ê¸° (ëŒ€ì•ˆ)
        new_key_file = 'new-service-account-key.json'
        
        if os.path.exists(new_key_file):
            try:
                # JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
                with open(new_key_file, 'r', encoding='utf-8') as f:
                    credentials_data = json.load(f)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: ìƒˆë¡œìš´_ì„œë¹„ìŠ¤_ê³„ì •_ì´ë©”ì¼@test-92f50.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì„ í¸ì§‘ìë¡œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
            except Exception as e:
                st.error(f"âŒ ìƒˆë¡œìš´ í‚¤ íŒŒì¼ ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                return None
            except Exception as e:
                st.error(f"âŒ ìƒˆë¡œìš´ í‚¤ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                return None
        
        # ë°©ë²• 2: í™˜ê²½ë³€ìˆ˜ì—ì„œ JSON í‚¤ ì½ê¸° (ëŒ€ì•ˆ)
        google_credentials_json = os.getenv('GOOGLE_CREDENTIALS_JSON')
        
        if google_credentials_json:
            try:
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: firebase-adminsdk-fbsvc@test-92f50.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— í¸ì§‘ì ê¶Œí•œìœ¼ë¡œ ê³µìœ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
                    
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                st.info("í™˜ê²½ë³€ìˆ˜ GOOGLE_CREDENTIALS_JSONì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            except Exception as e:
                st.error(f"âŒ ì¸ì¦ ì •ë³´ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                st.info("""
                **PEM íŒŒì¼ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:**
                1. private_keyì˜ ê°œí–‰ ë¬¸ì í™•ì¸
                2. JSON í‚¤ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
                3. ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ í™•ì¸
                4. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
                """)
                return None
        
        # ë°©ë²• 2: Streamlit secretsì—ì„œ JSON í‚¤ ì½ê¸° (ë°±ì—…)
        if hasattr(st, 'secrets') and 'GOOGLE_CREDENTIALS_JSON' in st.secrets:
            try:
                st.info("ğŸ” Streamlit secretsì—ì„œ ì¸ì¦ ì •ë³´ë¥¼ ì½ëŠ” ì¤‘...")
                google_credentials_json = st.secrets['GOOGLE_CREDENTIALS_JSON']
                
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                        st.info("âœ… private_key ê°œí–‰ ë¬¸ì ì •ê·œí™” ì™„ë£Œ")
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                st.info("ğŸ” ì¸ì¦ ì •ë³´ ìƒì„± ì¤‘...")
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                st.info("ğŸ” gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                st.info("ğŸ” êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
                try:
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì—°ê²° í™•ì¸
                    test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                    st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ!")
                    return client
                except Exception as test_error:
                    st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                    st.info("""
                    **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                    1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: firebase-adminsdk-fbsvc@test-92f50.iam.gserviceaccount.com
                    2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                    3. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— í¸ì§‘ì ê¶Œí•œìœ¼ë¡œ ê³µìœ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    """)
                    return None
                    
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                st.info("Streamlit secretsì˜ GOOGLE_CREDENTIALS_JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            except Exception as e:
                st.error(f"âŒ Streamlit secrets ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                return None
        
        # ë°©ë²• 3: JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
        json_file_path = "test-92f50-a704ebe1984f.json"
        if os.path.exists(json_file_path):
            try:
                st.info(f"ğŸ” JSON íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ë¥¼ ì½ëŠ” ì¤‘: {json_file_path}")
                
                creds = Credentials.from_service_account_file(
                    json_file_path,
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                return client
            except Exception as e:
                st.error(f"âŒ JSON íŒŒì¼ ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                st.info(f"íŒŒì¼ ê²½ë¡œ: {json_file_path}")
                return None
        
        # ë°©ë²• 4: ê¸°ë³¸ ì¸ì¦ ì •ë³´ ì‚¬ìš© (ê°œë°œìš©)
        st.warning("âš ï¸ í™˜ê²½ë³€ìˆ˜, Streamlit secrets, JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("""
        **êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì • ë°©ë²•:**
        
        1. **í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¶Œì¥):**
           - GOOGLE_CREDENTIALS_JSON í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        
        2. **Streamlit secrets ì„¤ì •:**
           - .streamlit/secrets.toml íŒŒì¼ì— GOOGLE_CREDENTIALS_JSON ì„¤ì •
        
        3. **JSON íŒŒì¼ ì‚¬ìš©:**
           - test-92f50-a704ebe1984f.json íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸
        
        4. **ì„œë¹„ìŠ¤ ê³„ì • ì„¤ì •:**
           - êµ¬ê¸€ í´ë¼ìš°ë“œ ì½˜ì†”ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ìƒì„±
           - êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ ê³µìœ 
        """)
        
        # ê°œë°œìš© ë”ë¯¸ í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì‹¤ì œ ì—°ê²°ì€ ì•ˆë¨)
        return None
            
    except Exception as e:
        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        st.info("""
        **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:**
        1. JSON í‚¤ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
        2. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸
        3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
        4. private_keyì˜ ê°œí–‰ ë¬¸ì í˜•ì‹ í™•ì¸
        """)
        return None

def load_data_from_sheet(client, sheet_name="power_data", sheet_id=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ (ë¹„ìºì‹œ ì›ë³¸)"""
    try:
        # ì‹œíŠ¸ ì—´ê¸° (IDê°€ ì œê³µëœ ê²½ìš° IDë¡œ, ì•„ë‹ˆë©´ ì´ë¦„ìœ¼ë¡œ)
        if sheet_id and sheet_id.strip():
            sheet = client.open_by_key(sheet_id).sheet1
        else:
            sheet = client.open(sheet_name).sheet1
        
        # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_values = sheet.get_all_values()
        
        if len(all_values) == 0:
            st.error("âŒ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
        headers = all_values[0]
        data_rows = all_values[1:]
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(data_rows, columns=headers)
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
        numeric_columns = ['ìµœê³ ê¸°ì˜¨', 'í‰ê· ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ìµœëŒ€ìˆ˜ìš”', 'ì²´ê°ì˜¨ë„']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ë‚ ì§œ ì»¬ëŸ¼ì„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
        if 'ë‚ ì§œ' in df.columns:
            try:
                # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
                df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
            except Exception as e:
                st.warning(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return df
    except Exception as e:
        st.error(f"âŒ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

@st.cache_data(show_spinner=False, ttl=300)
def load_data_from_sheet_cached(sheet_name="power_data", sheet_id=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ (ìºì‹œ) - 5ë¶„ TTL"""
    client = setup_google_sheets()
    if client is None:
        return None
    return load_data_from_sheet(client, sheet_name, sheet_id)

def save_data_to_sheet(client, data, sheet_name="power_data", sheet_id=None, original_data=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì— ë°ì´í„° ì €ì¥ (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)"""
    try:
        # ì‹œíŠ¸ ì—´ê¸° (IDê°€ ì œê³µëœ ê²½ìš° IDë¡œ, ì•„ë‹ˆë©´ ì´ë¦„ìœ¼ë¡œ)
        if sheet_id and sheet_id.strip():
            sheet = client.open_by_key(sheet_id).sheet1
        else:
            sheet = client.open(sheet_name).sheet1
        
        # ì›” ì»¬ëŸ¼ ì œê±° (ë‚´ë¶€ ê³„ì‚°ìš©ì´ë¯€ë¡œ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•˜ì§€ ì•ŠìŒ)
        data_to_save = data.copy()
        if 'ì›”' in data_to_save.columns:
            data_to_save = data_to_save.drop(columns=['ì›”'])
        
        # ì›ë³¸ ë°ì´í„°ë„ ì›” ì»¬ëŸ¼ ì œê±°í•˜ì—¬ ë¹„êµ
        original_data_to_compare = None
        if original_data is not None:
            original_data_to_compare = original_data.copy()
            if 'ì›”' in original_data_to_compare.columns:
                original_data_to_compare = original_data_to_compare.drop(columns=['ì›”'])
        
        # ì›ë³¸ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš° ë³€ê²½ëœ ë¶€ë¶„ë§Œ ê°ì§€
        if original_data_to_compare is not None:
            # ë³€ê²½ëœ í–‰ê³¼ ì—´ ê°ì§€
            changed_rows = []
            changed_columns = []
            
            # ë°ì´í„° íƒ€ì… í†µì¼ì„ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
            data_str = data_to_save.astype(str)
            original_str = original_data_to_compare.astype(str)
            
            # ë³€ê²½ëœ í–‰ ê°ì§€
            for idx in range(len(data_to_save)):
                if idx < len(original_str) and not data_str.iloc[idx].equals(original_str.iloc[idx]):
                    changed_rows.append(idx + 2)  # +2ëŠ” í—¤ë”(1)ì™€ 0-based ì¸ë±ìŠ¤(1) ë•Œë¬¸
            
            # ë³€ê²½ëœ ì—´ ê°ì§€
            for col in data_to_save.columns:
                if col in original_str.columns and not data_str[col].equals(original_str[col]):
                    changed_columns.append(col)
            
            # ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸ (ìµœì í™”ëœ ë°°ì¹˜ ë°©ì‹)
            if changed_rows:
                # ë³€ê²½ëœ í–‰ë“¤ì„ í•˜ë‚˜ì˜ ì—°ì†ëœ ë²”ìœ„ë¡œ ê·¸ë£¹í™”
                changed_rows.sort()  # í–‰ ë²ˆí˜¸ ì •ë ¬
                
                # ì—°ì†ëœ í–‰ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                row_groups = []
                current_group = [changed_rows[0]]
                
                for i in range(1, len(changed_rows)):
                    if changed_rows[i] == changed_rows[i-1] + 1:
                        # ì—°ì†ëœ í–‰
                        current_group.append(changed_rows[i])
                    else:
                        # ë¶ˆì—°ì†ëœ í–‰ - ìƒˆ ê·¸ë£¹ ì‹œì‘
                        row_groups.append(current_group)
                        current_group = [changed_rows[i]]
                
                row_groups.append(current_group)  # ë§ˆì§€ë§‰ ê·¸ë£¹ ì¶”ê°€
                
                # ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ ë²”ìœ„ë¡œ ì—…ë°ì´íŠ¸
                for group in row_groups:
                    start_row = group[0]
                    end_row = group[-1]
                    
                    # í•´ë‹¹ ë²”ìœ„ì˜ ë°ì´í„° ì¶”ì¶œ
                    group_data = data_to_save.iloc[start_row-2:end_row-1]  # -2ëŠ” ì¸ë±ìŠ¤ ì¡°ì •
                    
                    # ê° í–‰ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    group_values = []
                    for _, row in group_data.iterrows():
                        row_values = []
                        for val in row:
                            if pd.isna(val):
                                row_values.append('')
                            elif isinstance(val, pd.Timestamp):
                                row_values.append(val.strftime('%Y-%m-%d'))
                            elif isinstance(val, str) and 'T' in val:
                                try:
                                    date_obj = pd.to_datetime(val)
                                    row_values.append(date_obj.strftime('%Y-%m-%d'))
                                except:
                                    row_values.append(str(val))
                            else:
                                row_values.append(str(val))
                        group_values.append(row_values)
                    
                    # ë²”ìœ„ ì—…ë°ì´íŠ¸ (ì—°ì†ëœ í–‰ë“¤ì„ í•œ ë²ˆì—)
                    range_name = f'A{start_row}:{chr(65 + len(group_values[0]) - 1)}{end_row}'
                    
                    # ì„œì‹ ë³µì‚¬: ë°”ë¡œ ìœ„ í–‰ì˜ ì„œì‹ì„ ë”°ë¼ê°€ë„ë¡ ì„¤ì •
                    try:
                        if APPLY_SHEET_FORMATTING and start_row > 2:  # ì˜µì…˜: ì„œì‹ ì ìš©
                            format_range = f'A{start_row}:{chr(65 + len(group_values[0]) - 1)}{end_row}'
                            sheet.format(format_range, {
                                "textFormat": {
                                    "fontSize": 11,
                                    "fontFamily": "Arial"
                                }
                            })
                    except Exception as e:
                        st.warning(f"âš ï¸ ì„œì‹ ì ìš© ì‹¤íŒ¨: {str(e)}")
                    
                    # ë°ì´í„° ì—…ë°ì´íŠ¸
                    # ë¹ ë¥¸ ì—…ë°ì´íŠ¸(ë°°ì¹˜) ëª¨ë“œ
                    sheet.update(range_name, group_values, value_input_option='RAW')
                
                return True, f"âœ… {len(changed_rows)}ê°œ í–‰ì´ {len(row_groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        # ì›ë³¸ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì „ì²´ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°
        # ë‚ ì§œ ì»¬ëŸ¼ì„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
        for col in data_to_save.columns:
            if data_to_save[col].dtype == 'datetime64[ns]':
                data_to_save[col] = data_to_save[col].dt.strftime('%Y-%m-%d')
            elif data_to_save[col].dtype == 'object':
                # ë¬¸ìì—´ ì»¬ëŸ¼ì—ì„œ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸
                try:
                    # ì²« ë²ˆì§¸ ìœ íš¨í•œ ê°’ìœ¼ë¡œ ë‚ ì§œ í˜•ì‹ í™•ì¸
                    first_valid = data_to_save[col].dropna().iloc[0] if len(data_to_save[col].dropna()) > 0 else None
                    if first_valid and isinstance(first_valid, str) and ('T' in first_valid or '-' in first_valid):
                        # ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œë„
                        data_to_save[col] = pd.to_datetime(data_to_save[col], errors='coerce').dt.strftime('%Y-%m-%d')
                except:
                    pass  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
        
        # ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì—…ë°ì´íŠ¸ (API í˜¸ì¶œ ìµœì†Œí™”)
        all_values = [data_to_save.columns.tolist()]  # í—¤ë”
        for _, row in data_to_save.iterrows():
            # ê° ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            row_values = [str(val) if val is not None else '' for val in row.tolist()]
            all_values.append(row_values)
        
        # ì‹œíŠ¸ë¥¼ í•œ ë²ˆì— ì—…ë°ì´íŠ¸
        sheet.clear()
        sheet.update('A1', all_values, value_input_option='RAW')
        
        return True, "âœ… ì „ì²´ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        st.error(f"âŒ ì‹œíŠ¸ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False, f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}"

# ì‚¬ì´ë“œë°” ì œê±°ë¨ (ìš”ì²­ì— ë”°ë¼ ë¹„í‘œì‹œ)

# --- 0. ë°ì´í„° ë¡œë”© ë° í¸ì§‘ ---
st.header("ğŸ“ Step 0: ë°ì´í„° ë¡œë”© ë° í¸ì§‘")

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
st.subheader("ğŸ” êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •")

client = setup_google_sheets()
if client is None:
    st.warning("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì´ ì¼ì‹œì ìœ¼ë¡œ ì§€ì—°ë©ë‹ˆë‹¤. ìºì‹œëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì • ì •ë³´
sheet_name = "ì‹œíŠ¸1"
sheet_id = "1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4"

# ë°ì´í„° ìë™ ë¡œë”© (ìºì‹œ ìš°ì„ )
if 'data' not in st.session_state:
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        data = load_data_from_sheet_cached(sheet_name, sheet_id)
        if data is None and client is not None:
            data = load_data_from_sheet(client, sheet_name, sheet_id)
        if data is not None:
            st.session_state.data = data
            st.session_state.original_data = data.copy()
        else:
            st.error("âŒ ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

# ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
if 'data' not in st.session_state:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

data = st.session_state.data

# ë°ì´í„° í¸ì§‘ ê¸°ëŠ¥
st.subheader("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° í¸ì§‘")

# ë°ì´í„° ì •ë³´ í‘œì‹œ
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ì´ í–‰ ìˆ˜", f"{len(data):,}ê°œ")
with col2:
    st.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{len(data.columns)}ê°œ")
with col3:
    # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
    if 'ë‚ ì§œ' in data.columns:
        try:
            # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            date_data = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
            start_date = date_data.min().strftime('%Y-%m-%d')
        except (ValueError, TypeError) as e:
            st.warning(f"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            start_date = "N/A"
    else:
        start_date = "N/A"
    st.metric("ì‹œì‘ì¼", start_date)
with col4:
    if 'ë‚ ì§œ' in data.columns:
        try:
            date_data = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
            end_date = date_data.max().strftime('%Y-%m-%d')
        except (ValueError, TypeError) as e:
            st.warning(f"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            end_date = "N/A"
    else:
        end_date = "N/A"
    st.metric("ì¢…ë£Œì¼", end_date)

# ë°ì´í„° í¸ì§‘ íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", "âœï¸ ë°ì´í„° í¸ì§‘", "ğŸ“ˆ í†µê³„ ì •ë³´"])

with tab1:
    st.subheader("ì „ì²´ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    
    # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
    display_data = data.copy()
    if 'ë‚ ì§œ' in display_data.columns:
        try:
            # datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
            display_data['ë‚ ì§œ'] = pd.to_datetime(display_data['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
        except Exception as e:
            st.warning(f"ë‚ ì§œ í‘œì‹œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
    
    st.dataframe(display_data, use_container_width=True)
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    csv = data.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ë°ì´í„°ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="power_data_edited.csv",
        mime="text/csv"
    )

with tab2:
    st.subheader("ë°ì´í„° í¸ì§‘")
    st.info("ì•„ë˜ì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ í¸ì§‘í•˜ê±°ë‚˜ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í¸ì§‘ í›„ 'ë³€ê²½ì‚¬í•­ ì ìš©' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    # í¸ì§‘ìš© ë°ì´í„° ì¤€ë¹„ (ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì„± í™•ë³´)
    if 'edit_data' not in st.session_state:
        # ì²˜ìŒ ë¡œë“œí•  ë•Œë§Œ í¸ì§‘ìš© ë°ì´í„° ì¤€ë¹„
        edit_data = data.copy()
        
        # ì›” ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±° (ë‚´ë¶€ ê³„ì‚°ìš©ì´ë¯€ë¡œ í¸ì§‘ ë¶ˆê°€)
        if 'ì›”' in edit_data.columns:
            edit_data = edit_data.drop(columns=['ì›”'])
        
        if 'ë‚ ì§œ' in edit_data.columns:
            try:
                # datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
                edit_data['ë‚ ì§œ'] = pd.to_datetime(edit_data['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
            except Exception as e:
                st.warning(f"ë‚ ì§œ í¸ì§‘ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.edit_data = edit_data
    else:
        # ì„¸ì…˜ ìƒíƒœì—ì„œ í¸ì§‘ìš© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        edit_data = st.session_state.edit_data
    
    # í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„
    edited_data = st.data_editor(
        edit_data,
        num_rows="dynamic",
        use_container_width=True,
        key="data_editor"
    )
    
    # ë³€ê²½ì‚¬í•­ ì ìš© ë²„íŠ¼
    if st.button("âœ… ë³€ê²½ì‚¬í•­ ì ìš©", type="primary"):
        with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì¤‘... (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)"):
            # í¸ì§‘ëœ ë°ì´í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ì— ë°˜ì˜
            data = edited_data.copy()
            
            # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ (í¸ì§‘ ì‹œ ë¬¸ìì—´ë¡œ í‘œì‹œë˜ì—ˆìœ¼ë¯€ë¡œ)
            if 'ë‚ ì§œ' in data.columns:
                try:
                    data['ë‚ ì§œ'] = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
                except Exception as e:
                    st.warning(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ì›” ì»¬ëŸ¼ ë‹¤ì‹œ ì¶”ê°€ (ë‚´ë¶€ ê³„ì‚°ìš©)
            if 'ë‚ ì§œ' in data.columns:
                try:
                    # ë‚ ì§œì—ì„œ ì›” ì¶”ì¶œí•˜ì—¬ ì›” ì»¬ëŸ¼ ì¶”ê°€
                    data['ì›”'] = pd.to_datetime(data['ë‚ ì§œ']).dt.month
                except Exception as e:
                    st.warning(f"ì›” ì»¬ëŸ¼ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            
            st.session_state.data = data
            
            # í¸ì§‘ìš© ë°ì´í„° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë‹¤ìŒ í¸ì§‘ì„ ìœ„í•´)
            if 'edit_data' in st.session_state:
                del st.session_state.edit_data
            
            # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ì— ì €ì¥ëœ ì›ë³¸ ë°ì´í„°)
            original_data = st.session_state.get('original_data', None)
            
            # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)
            success, message = save_data_to_sheet(client, data, sheet_name, sheet_id, original_data)
            
            if success:
                st.success(message)
                
                # ì›ë³¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë‹¤ìŒ í¸ì§‘ì„ ìœ„í•´)
                st.session_state.original_data = data.copy()
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.data_updated = True
                st.rerun()
            else:
                st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ API í•œë„ ì´ˆê³¼ë¡œ ì¸í•œ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        csv_updated = data.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=csv_updated,
            file_name="power_data_updated.csv",
            mime="text/csv"
        )
        
        # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì˜µì…˜
        st.subheader("ğŸ’¾ ì—‘ì…€ íŒŒì¼ ì €ì¥")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“Š ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥", type="secondary"):
                try:
                    # ì„ì‹œ ì—‘ì…€ íŒŒì¼ ìƒì„±
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        data.to_excel(writer, index=False, sheet_name='Power_Data')
                    
                    excel_buffer.seek(0)
                    st.download_button(
                        label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=excel_buffer.getvalue(),
                        file_name="power_data_updated.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    st.success("âœ… ì—‘ì…€ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"âŒ ì—‘ì…€ íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        with col2:
            st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ê°€ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤!")
    
    # ì›ë³¸ êµ¬ê¸€ì‹œíŠ¸ ì£¼ì†Œ
    st.subheader("ğŸ“Š ì›ë³¸ êµ¬ê¸€ì‹œíŠ¸")
    st.markdown("[ğŸ”— ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ë°ì´í„° ë°”ë¡œ ê°€ê¸°](https://docs.google.com/spreadsheets/d/1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4/edit?gid=0#gid=0)")

with tab3:
    st.subheader("ë°ì´í„° í†µê³„ ì •ë³´")
    
    # ìˆ˜ì¹˜í˜• ë°ì´í„° í†µê³„
    numeric_cols = data.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        st.write("**ìˆ˜ì¹˜í˜• ë°ì´í„° í†µê³„:**")
        st.dataframe(data[numeric_cols].describe(), use_container_width=True)
    
    # ë²”ì£¼í˜• ë°ì´í„° í†µê³„
    categorical_cols = data.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        st.write("**ë²”ì£¼í˜• ë°ì´í„° í†µê³„:**")
        for col in categorical_cols:
            st.write(f"**{col}:**")
            value_counts = data[col].value_counts()
            st.dataframe(value_counts, use_container_width=True)
    
    # ê²°ì¸¡ê°’ ì •ë³´
    missing_data = data.isnull().sum()
    if missing_data.sum() > 0:
        st.write("**ê²°ì¸¡ê°’ ì •ë³´:**")
        st.dataframe(missing_data[missing_data > 0], use_container_width=True)
    else:
        st.success("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!")

st.markdown("---")

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
st.header("ğŸ“‹ Step 1: ë°ì´í„° ì¤€ë¹„")
with st.spinner("ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ì¤‘..."):
    # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    if 'ë‚ ì§œ' in data.columns:
        data['ë‚ ì§œ'] = pd.to_datetime(data['ë‚ ì§œ'])
    else:
        st.error("âŒ 'ë‚ ì§œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ìš”ì¼/í‰ì¼ íŒŒìƒ (ì—†ìœ¼ë©´ ìƒì„±)
    try:
        weekday_map = {0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'}
        if 'ìš”ì¼' not in data.columns:
            data['ìš”ì¼'] = data['ë‚ ì§œ'].dt.weekday.map(weekday_map)
        if 'í‰ì¼' not in data.columns:
            data['í‰ì¼'] = np.where(data['ë‚ ì§œ'].dt.weekday < 5, 'í‰ì¼', 'ì£¼ë§')
    except Exception:
        pass
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
    required_columns = ['ìµœê³ ê¸°ì˜¨', 'í‰ê· ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ìµœëŒ€ìˆ˜ìš”', 'í‰ì¼', 'ì²´ê°ì˜¨ë„']
    missing_columns = [col for col in required_columns if col not in data.columns]
    
    if missing_columns:
        st.warning(f"âš ï¸ ì¼ë¶€ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        st.info("ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆì–´ë„ ê°€ëŠ¥í•œ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤.")
        
        # ìµœì†Œí•œì˜ í•„ìˆ˜ ì»¬ëŸ¼ë§Œ í™•ì¸ (ìµœì €ìˆ˜ìš” ì œì™¸)
        essential_columns = ['ë‚ ì§œ', 'ìµœëŒ€ìˆ˜ìš”']
        essential_missing = [col for col in essential_columns if col not in data.columns]
        
        if essential_missing:
            st.error(f"âŒ í•µì‹¬ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {essential_missing}")
            st.info("ìµœì†Œí•œ ë‚ ì§œ, ìµœëŒ€ìˆ˜ìš” ì»¬ëŸ¼ì€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
    
    # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° í™•ì¸
    gas_columns = ['ê°€ìŠ¤ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€']
    available_gas_columns = [col for col in gas_columns if col in data.columns]
    
    if available_gas_columns:
        st.success(f"âœ… ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê°€ëŠ¥: {', '.join(available_gas_columns)} ì»¬ëŸ¼ ë°œê²¬")
        if len(available_gas_columns) == 2:
            st.info("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥")
        else:
            st.warning(f"âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•´ ì¶”ê°€ ì»¬ëŸ¼ í•„ìš”: {[col for col in gas_columns if col not in available_gas_columns]}")
    else:
        st.info("â„¹ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ (ê°€ìŠ¤ìˆ˜ìš”, íƒœì–‘ê´‘ìµœëŒ€)")
    
    # ë°ì´í„° ì •ë³´ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ë°ì´í„° ìˆ˜", f"{len(data):,}ê°œ")
    with col2:
        st.metric("ì‹œì‘ì¼", data['ë‚ ì§œ'].min().strftime('%Y-%m-%d'))
    with col3:
        st.metric("ì¢…ë£Œì¼", data['ë‚ ì§œ'].max().strftime('%Y-%m-%d'))

st.markdown("---")

# --- 2. íŠ¹ì§• ê³µí•™ ë° ë°ì´í„° ì •ì œ ---
st.header("ğŸ”§ Step 2: íŠ¹ì§• ê³µí•™ ë° ë°ì´í„° ì •ì œ")
with st.spinner("íŠ¹ì§• ê³µí•™ì„ ìˆ˜í–‰ ì¤‘..."):
    data['ì›”'] = data['ë‚ ì§œ'].dt.month
    data['ì¼'] = data['ë‚ ì§œ'].dt.day
    data['ì—°ë„'] = data['ë‚ ì§œ'].dt.year
    # ê³µíœ´ì¼ í”Œë˜ê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í‰ì¼ ì»¬ëŸ¼ 'í‰ì¼/íœ´ì¼'ì— í†µí•©)
    
    # ìš”ì¼ ë”ë¯¸ ìƒì„±, í‰ì¼ì€ ìˆ˜ë™ ì´ì§„ í”Œë˜ê·¸ë¡œ ì²˜ë¦¬(ê°’: 'í‰ì¼' ë˜ëŠ” 'íœ´ì¼')
    data_processed = pd.get_dummies(data, columns=['ìš”ì¼'], drop_first=True)
    try:
        if 'í‰ì¼' in data.columns:
            data_processed['í‰ì¼_í‰ì¼'] = (data['í‰ì¼'].astype(str) == 'í‰ì¼').astype(int)
        else:
            # ë°±ì—…: ìš”ì¼ë¡œ ì¶”ì • (ì£¼ë§ì´ë©´ 0)
            data_processed['í‰ì¼_í‰ì¼'] = (data['ë‚ ì§œ'].dt.weekday < 5).astype(int)
    except Exception:
        data_processed['í‰ì¼_í‰ì¼'] = 0
    # ì–´ì œ ìˆ˜ìš” ë˜ê·¸
    data_processed['ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”'] = data_processed['ìµœëŒ€ìˆ˜ìš”'].shift(1)
    
    # ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìƒì„± (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
    try:
        is_summer_mask = data_processed['ì›”'].isin([5, 6, 7, 8, 9])
        is_winter_mask = data_processed['ì›”'].isin([10, 11, 12, 1, 2, 3, 4])
        
        # ê°œì„ ëœ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§•: ëƒ‰ë°©ê°•ë„/ë‚œë°©ê°•ë„
        st.subheader("ğŸŒ¡ï¸ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìµœì í™”")
        cooling_base_temp = 25.0
        heating_base_temp = 10.0
        # ëƒ‰ë°©ê°•ë„: ì²´ê°ì˜¨ë„(ìˆìœ¼ë©´) ì—†ìœ¼ë©´ ìµœê³ ê¸°ì˜¨ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        if 'ì²´ê°ì˜¨ë„' in data_processed.columns:
            temp_for_cooling = data_processed['ì²´ê°ì˜¨ë„']
        elif 'ìµœê³ ê¸°ì˜¨' in data_processed.columns:
            temp_for_cooling = data_processed['ìµœê³ ê¸°ì˜¨']
        else:
            st.error("âŒ ì˜¨ë„ ê´€ë ¨ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œí•œ ìµœê³ ê¸°ì˜¨ ë˜ëŠ” ì²´ê°ì˜¨ë„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
        data_processed['ëƒ‰ë°©ê°•ë„'] = (pd.to_numeric(temp_for_cooling, errors='coerce') - cooling_base_temp).clip(lower=0)
        
        # ë‚œë°©ê°•ë„: ìµœì €ê¸°ì˜¨ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        if 'ìµœì €ê¸°ì˜¨' in data_processed.columns:
            temp_for_heating = pd.to_numeric(data_processed['ìµœì €ê¸°ì˜¨'], errors='coerce')
            data_processed['ë‚œë°©ê°•ë„'] = (heating_base_temp - temp_for_heating).clip(lower=0)
        else:
            st.warning("âš ï¸ ìµœì €ê¸°ì˜¨ì´ ì—†ì–´ ë‚œë°©ê°•ë„ëŠ” 0ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
            data_processed['ë‚œë°©ê°•ë„'] = 0.0
        st.success("âœ… ëƒ‰ë°©/ë‚œë°© ê°•ë„ë¥¼ ë°˜ì˜í•œ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìƒì„± ì™„ë£Œ!")
        # ê³„ì ˆ ë§ˆìŠ¤í¬ ì ìš©: ì—¬ë¦„ì—” ëƒ‰ë°©ê°•ë„ë§Œ, ê²¨ìš¸ì—” ë‚œë°©ê°•ë„ë§Œ ì‚¬ìš©
        data_processed['ëƒ‰ë°©ê°•ë„'] = data_processed['ëƒ‰ë°©ê°•ë„'] * is_summer_mask.astype(int)
        data_processed['ë‚œë°©ê°•ë„'] = data_processed['ë‚œë°©ê°•ë„'] * is_winter_mask.astype(int)

        # ì¶”ê°€ ì˜¨ë„ íŒŒìƒ: ì¼êµì°¨(ìµœê³ -ìµœì €) (ê°€ëŠ¥í•  ë•Œ)
        try:
            if 'ìµœê³ ê¸°ì˜¨' in data_processed.columns and 'ìµœì €ê¸°ì˜¨' in data_processed.columns:
                data_processed['ì¼êµì°¨'] = pd.to_numeric(data_processed['ìµœê³ ê¸°ì˜¨'], errors='coerce') - pd.to_numeric(data_processed['ìµœì €ê¸°ì˜¨'], errors='coerce')
        except Exception:
            pass

        # ì´ë™í‰ê· (ëˆ„ìˆ˜ ë°©ì§€: shift(1) í›„ rolling)
        try:
            data_processed['7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”'] = data_processed['ìµœëŒ€ìˆ˜ìš”'].shift(1).rolling(window=7, min_periods=1).mean()
            data_processed['14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”'] = data_processed['ìµœëŒ€ìˆ˜ìš”'].shift(1).rolling(window=14, min_periods=1).mean()
            data_processed['ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = data_processed['ìµœëŒ€ìˆ˜ìš”'].shift(7)
        except Exception:
            pass

        # ìµœì‹  ê´€ì¸¡ ê¸°ë°˜ ë™ì  ì…ë ¥ ê¸°ë³¸ê°’ ì €ì¥ (ì˜ˆì¸¡ ì‹œ ì‚¬ìš©)
        try:
            st.session_state.dynamic_max_features = {}
            # ì¬ê·€ ì˜ˆì¸¡ì„ ìœ„í•œ ìµœê·¼ 14ì¼ íƒ€ê¹ƒ ì‹œê³„ì—´ ì €ì¥
            try:
                st.session_state.max_series_tail = list(pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce').dropna().tail(14).values)
            except Exception:
                st.session_state.max_series_tail = []
        except Exception:
            st.session_state.dynamic_max_features = {}
            st.session_state.max_series_tail = []
            
    except Exception as e:
        st.error(f"âŒ ì˜¨ë„ íŠ¹ì§• ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()
    
    # ê°€ìŠ¤ìˆ˜ìš” íŠ¹ì§• ê³µí•™
    if 'ê°€ìŠ¤ìˆ˜ìš”' in data_processed.columns and 'íƒœì–‘ê´‘ìµœëŒ€' in data_processed.columns:
        # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜
        data_processed['ê°€ìŠ¤ìˆ˜ìš”'] = pd.to_numeric(data_processed['ê°€ìŠ¤ìˆ˜ìš”'], errors='coerce')
        data_processed['íƒœì–‘ê´‘ìµœëŒ€'] = pd.to_numeric(data_processed['íƒœì–‘ê´‘ìµœëŒ€'], errors='coerce')
        # ì”ì—¬ë¶€í•˜(ìµœëŒ€ìˆ˜ìš” - íƒœì–‘ê´‘ìµœëŒ€)
        if 'ìµœëŒ€ìˆ˜ìš”' in data_processed.columns:
            try:
                data_processed['ì”ì—¬ë¶€í•˜'] = pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce') - data_processed['íƒœì–‘ê´‘ìµœëŒ€']
            except Exception:
                pass
            # ìµœëŒ€ìˆ˜ìš” ëŒ€ë¹„ ë¹„ìœ¨ íŠ¹ì§•ë“¤ (ê°€ìŠ¤ ì œì™¸, ëˆ„ì„¤ ë°©ì§€)
            try:
                denom = data_processed['ìµœëŒ€ìˆ˜ìš”'].replace(0, np.nan)
                data_processed['ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨'] = (data_processed['íƒœì–‘ê´‘ìµœëŒ€'] / denom).fillna(0.0)
                data_processed['ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨'] = (data_processed['ì”ì—¬ë¶€í•˜'] / denom).fillna(0.0)
            except Exception:
                pass

        # (ê°€ìŠ¤+íƒœì–‘ê´‘)/ìµœëŒ€ìˆ˜ìš” ì´ë¹„ìœ¨ì˜ í‰ì¼/ì£¼ë§ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì˜ˆì‚°í˜• ê°€ìŠ¤ ê¸°ì¤€ì¹˜ ìƒì„±
        try:
            denom_total = data_processed['ìµœëŒ€ìˆ˜ìš”'].replace(0, np.nan)
            total_ratio = (data_processed['ê°€ìŠ¤ìˆ˜ìš”'] + data_processed['íƒœì–‘ê´‘ìµœëŒ€']) / denom_total
            # í‰ì¼ í”Œë˜ê·¸ íŒŒìƒ (ì›-í•«ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ì—ì„œ ìœ ë„)
            if 'í‰ì¼_í‰ì¼' in data_processed.columns:
                is_weekday_series = data_processed['í‰ì¼_í‰ì¼']
            else:
                is_weekday_series = (data['í‰ì¼'] == 'í‰ì¼').astype(int) if 'í‰ì¼' in data.columns else pd.Series(0, index=data_processed.index)

            weekday_mean = total_ratio[is_weekday_series == 1].mean()
            weekend_mean = total_ratio[is_weekday_series == 0].mean()
            global_mean = total_ratio.mean()

            if pd.isna(weekday_mean):
                weekday_mean = global_mean
            if pd.isna(weekend_mean):
                weekend_mean = global_mean

            # ì„¸ì…˜ì— ì €ì¥ (ì˜ˆì¸¡ ì‹œ ì‚¬ìš©)
            st.session_state.gas_total_ratio_weekday = float(weekday_mean) if not pd.isna(weekday_mean) else 0.0
            st.session_state.gas_total_ratio_weekend = float(weekend_mean) if not pd.isna(weekend_mean) else 0.0

            # í–‰ë³„ ì˜ˆì‚° ë¹„ìœ¨ ì„ íƒ í›„ ëª©í‘œ ê°€ìŠ¤ëŸ‰ ê³„ì‚°: max*ratio - solar
            ratio_used = np.where(is_weekday_series == 1, st.session_state.gas_total_ratio_weekday, st.session_state.gas_total_ratio_weekend)
            data_processed['ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°'] = (data_processed['ìµœëŒ€ìˆ˜ìš”'] * ratio_used - data_processed['íƒœì–‘ê´‘ìµœëŒ€']).clip(lower=0)
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ì»¬ëŸ¼ ë¯¸ìƒì„±
            pass
        
        # ê²°ì¸¡ê°’ ì œê±° í›„ íŠ¹ì§• ê³µí•™
        gas_data_clean = data_processed[['ê°€ìŠ¤ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€']].dropna()
        if len(gas_data_clean) > 0:
            data_processed['ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”'] = data_processed['ê°€ìŠ¤ìˆ˜ìš”'].shift(1)
            # ëˆ„ì„¤ ë°©ì§€: ë³€í™”ìœ¨ì€ tì‹œì ì´ ì•„ë‹ˆë¼ (t-1,t-2)ë¡œ ê³„ì‚°
            data_processed['ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨'] = data_processed['ê°€ìŠ¤ìˆ˜ìš”'].pct_change().shift(1)
            # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìµœì‹  ê´€ì¸¡ ë˜ê·¸ ë³´ê´€
            try:
                last_two_gas = pd.to_numeric(gas_data_clean['ê°€ìŠ¤ìˆ˜ìš”'], errors='coerce').dropna().tail(2).values
                if len(last_two_gas) >= 1:
                    st.session_state.last_gas = float(last_two_gas[-1])
                if len(last_two_gas) == 2:
                    st.session_state.prev_gas = float(last_two_gas[0])
            except Exception:
                pass
            st.success("âœ… ì „ë ¥ìˆ˜ìš” ë° ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
        else:
            st.warning("âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„°ê°€ ìˆ«ìë¡œ ë³€í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.success("âœ… ì „ë ¥ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
    else:
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
    
    # í•µì‹¬ í•™ìŠµ í”¼ì²˜ ìœ„ì£¼ë¡œ ê²°ì¸¡ ì œê±° (ë¶ˆí•„ìš”í•œ ì „ì²´ ë“œë ë°©ì§€)
    essential_cols = ['ìµœëŒ€ìˆ˜ìš”','íƒœì–‘ê´‘ìµœëŒ€','ìµœê³ ê¸°ì˜¨','í‰ê· ê¸°ì˜¨','ì²´ê°ì˜¨ë„','ì›”','ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”','7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”','14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”','ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”']
    essential_cols = [c for c in essential_cols if c in data_processed.columns]
    data_processed.dropna(subset=essential_cols, inplace=True)
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ì •ë³´
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì •ì œ í›„ ë°ì´í„° ìˆ˜", f"{len(data_processed):,}ê°œ")
    with col2:
        st.metric("íŠ¹ì§• ë³€ìˆ˜ ìˆ˜", f"{len(data_processed.columns)}ê°œ")
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ” ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(data_processed.head(10), use_container_width=True)

st.markdown("---")

# --- 3. ëª¨ë¸ ë³€ìˆ˜ ë° ë°ì´í„° ë¶„ë¦¬ ---
st.header("ğŸ¯ Step 3: ëª¨ë¸ ë³€ìˆ˜ ë° ë°ì´í„° ë¶„ë¦¬")

# í‰ê· ê¸°ì˜¨ì„ ëª¨ë¸ íŠ¹ì§•ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í–¥í›„ í•„ìš” ì‹œ Trueë¡œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ ë³€ìˆ˜ë§Œ ìœ ì§€)
include_avg_temp_feature = False

# [ìµœëŒ€ìˆ˜ìš” ëª¨ë¸] (ì—¬ë¦„ì² ì—ëŠ” ì²´ê°ì˜¨ë„ ì‚¬ìš©)
_base_max = ['ëƒ‰ë°©ê°•ë„', 'ë‚œë°©ê°•ë„', 'ì›”', 'ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”', '7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”', '14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”', 'ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”']
if include_avg_temp_feature:
    _base_max.insert(1, 'í‰ê· ê¸°ì˜¨')

# ì¶”ê°€ë¡œ ìµœì €/ìµœê³ /ì²´ê°/ì¼êµì°¨ê¹Œì§€ í•¨ê»˜ ì‚¬ìš© (ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
_temp_extras = [f for f in ['ìµœê³ ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ì²´ê°ì˜¨ë„', 'ì¼êµì°¨'] if f in data_processed.columns]

# ìš”ì¼, í‰ì¼ ë”ë¯¸ í¬í•¨
_dummies = [col for col in data_processed if col.startswith('ìš”ì¼_') or col.startswith('í‰ì¼_')]

features_max = _base_max + _temp_extras + _dummies
X_max = data_processed[features_max]
y_max = data_processed['ìµœëŒ€ìˆ˜ìš”']

# ìµœì €ìˆ˜ìš” ëª¨ë¸ ì œê±° - ìµœëŒ€ìˆ˜ìš” ëª¨ë¸ë§Œ ì‚¬ìš©

# ê³ ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
test_size = 0.2
n_estimators = 100
random_state = 42

# ë‹¨ì¼ ëª¨ë¸ìš© ë°ì´í„° ë¶„í•  - ì‹œê°„ìˆœ ë¶„í•  (í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ì œê±°)
X_max_train, X_max_test, y_max_train, y_max_test = chronological_split(
    X_max, y_max, data_processed['ë‚ ì§œ'], test_size=test_size
)

# ë³€ìˆ˜ ì •ë³´ í‘œì‹œ
st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜")
st.write(f"íŠ¹ì§• ë³€ìˆ˜: {len(features_max)}ê°œ")
# í‘œì‹œìš© ì´ë¦„ ë§¤í•‘: 'ëƒ‰ë°©ê°•ë„'/'ë‚œë°©ê°•ë„'ë¥¼ ì§ê´€ì ìœ¼ë¡œ í‘œì‹œ
_display_name_map = {
    'ëƒ‰ë°©ê°•ë„': 'ëƒ‰ë°©ê°•ë„(>25Â°C)',
    'ë‚œë°©ê°•ë„': 'ë‚œë°©ê°•ë„(<10Â°C)',
}
display_features_max = [_display_name_map.get(name, name) for name in features_max]
# í—¤ë” í–‰ì„ ì‚¬ìš©í•œ í•œ ì¤„ í‘œ
max_vars_df = pd.DataFrame([display_features_max], columns=[f'ë³€ìˆ˜{i+1}' for i in range(len(display_features_max))])
st.dataframe(max_vars_df, use_container_width=True)



# ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜ (ê°€ëŠ¥í•œ ê²½ìš°)
if 'ê°€ìŠ¤ìˆ˜ìš”' in data_processed.columns and 'íƒœì–‘ê´‘ìµœëŒ€' in data_processed.columns:
    st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜")
    # ìµœì†ŒÂ·í•µì‹¬ í”¼ì²˜ ìœ„ì£¼ êµ¬ì„± (ë‹¤ì¤‘ê³µì„ ì„±/ëˆ„ì„¤ ìœ„í—˜ ë‚®ì¶¤)
    features_gas = [
        'ìµœëŒ€ìˆ˜ìš”',          # ì´ ìŠ¤ì¼€ì¼
        'íƒœì–‘ê´‘ìµœëŒ€',        # ëŒ€ì²´ê´€ê³„ í•µì‹¬
        'ì”ì—¬ë¶€í•˜',          # ì”ì—¬ ì´ëŸ‰
        'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨',
        'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨',
        'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°',      # í‰ì¼/ì£¼ë§ ì´ë¹„ìœ¨ ì˜ˆì‚°
        'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”',     # ë˜ê·¸
        'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨',# ë˜ê·¸ ë³€í™”ìœ¨(ëˆ„ì„¤ ë°©ì§€)
        'í‰ì¼_í‰ì¼'          # í‰ì¼/ì£¼ë§ íš¨ê³¼
    ]
    available_gas_features = [col for col in features_gas if col in data_processed.columns]
    
    if len(available_gas_features) >= 2:  # ìµœì†Œ 2ê°œ ë³€ìˆ˜ í•„ìš”
        X_gas = data_processed[available_gas_features]
        y_gas = data_processed['ê°€ìŠ¤ìˆ˜ìš”']
        
        # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° ë¶„í•  - ì‹œê°„ìˆœ ë¶„í• 
        X_gas_train, X_gas_test, y_gas_train, y_gas_test = chronological_split(
            X_gas, y_gas, data_processed.loc[X_gas.index, 'ë‚ ì§œ'], test_size=test_size
        )
        
        st.write(f"íŠ¹ì§• ë³€ìˆ˜: {len(available_gas_features)}ê°œ")
        gas_vars_df = pd.DataFrame([available_gas_features], columns=[f'ë³€ìˆ˜{i+1}' for i in range(len(available_gas_features))])
        st.dataframe(gas_vars_df, use_container_width=True)
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë‹¨ì¼ ì „ì²´ ì„¸íŠ¸)
        st.session_state.X_gas_train = X_gas_train
        st.session_state.X_gas_test = X_gas_test
        st.session_state.y_gas_train = y_gas_train
        st.session_state.y_gas_test = y_gas_test
        st.session_state.features_gas = available_gas_features

        # í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ì„¸íŠ¸ ìƒì„±
        if 'í‰ì¼_í‰ì¼' in data_processed.columns:
            try:
                mask_weekday = data_processed['í‰ì¼_í‰ì¼'] == 1
            except Exception:
                mask_weekday = pd.Series(False, index=data_processed.index)
        else:
            # ì›ë³¸ 'í‰ì¼'ì—ì„œ ìœ ë„
            mask_weekday = (data['í‰ì¼'] == 'í‰ì¼') if 'í‰ì¼' in data.columns else pd.Series(False, index=data_processed.index)

        try:
            X_gas_wd = X_gas[mask_weekday]
            y_gas_wd = y_gas[mask_weekday]
            X_gas_we = X_gas[~mask_weekday]
            y_gas_we = y_gas[~mask_weekday]

            # ìµœì†Œ í‘œë³¸ í™•ì¸ í›„ ë¶„í• 
            if len(X_gas_wd) >= 20 and len(X_gas_we) >= 20:
                X_gas_wd_tr, X_gas_wd_te, y_gas_wd_tr, y_gas_wd_te = chronological_split(
                    X_gas_wd, y_gas_wd, data_processed.loc[X_gas_wd.index, 'ë‚ ì§œ'], test_size=test_size
                )
                X_gas_we_tr, X_gas_we_te, y_gas_we_tr, y_gas_we_te = chronological_split(
                    X_gas_we, y_gas_we, data_processed.loc[X_gas_we.index, 'ë‚ ì§œ'], test_size=test_size
                )

                st.session_state.X_gas_train_weekday = X_gas_wd_tr
                st.session_state.X_gas_test_weekday = X_gas_wd_te
                st.session_state.y_gas_train_weekday = y_gas_wd_tr
                st.session_state.y_gas_test_weekday = y_gas_wd_te

                st.session_state.X_gas_train_weekend = X_gas_we_tr
                st.session_state.X_gas_test_weekend = X_gas_we_te
                st.session_state.y_gas_train_weekend = y_gas_we_tr
                st.session_state.y_gas_test_weekend = y_gas_we_te
            else:
                st.warning("âš ï¸ í‰ì¼/ì£¼ë§ ë¶„ë¦¬ í•™ìŠµì„ ìœ„í•œ í‘œë³¸ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¨ì¼ ëª¨ë¸ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        except Exception:
            st.warning("âš ï¸ í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹¨ì¼ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("â„¹ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("---")

# --- 4. ëª¨ë¸ í•™ìŠµ (ë‹¨ì¼ ëª¨ë¸) ---
st.header("ğŸ¤– Step 4: ëª¨ë¸ í•™ìŠµ")
with st.spinner("ëª¨ë¸ì„ í•™ìŠµ ì¤‘..."):
    st.subheader("ğŸ“ˆ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ")
    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (ê°„ë‹¨ íŠœë‹ ì ìš©)
    try:
        rf_max = tune_rf_model(X_max_train, y_max_train, random_state=random_state)
    except Exception:
        rf_max = train_rf_model(X_max_train, y_max_train, n_estimators=n_estimators, random_state=random_state)
    
    # ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ (ë‹¨ì¼ ëª¨ë¸ë¡œ ê³ ì •)
    if hasattr(st.session_state, 'features_gas'):
        features_for_constraints = st.session_state.features_gas
        constraint_map = {
            'ìµœëŒ€ìˆ˜ìš”': 1,
            'íƒœì–‘ê´‘ìµœëŒ€': -1,
            'ì”ì—¬ë¶€í•˜': 1,
            'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨': -1,
            'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨': 1,
            'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°': 1,
            'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”': 0,
            'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨': 0,
            'í‰ì¼_í‰ì¼': 0,
        }
        monotone_constraints = [constraint_map.get(f, 0) for f in features_for_constraints]

        # ë‹¨ì¼ ëª¨ë¸ë¡œ í•™ìŠµ
        st.session_state.gas_model = train_lgbm_gas_model(
            st.session_state.X_gas_train,
            st.session_state.y_gas_train,
            monotone_constraints=monotone_constraints,
            n_estimators=300,
            learning_rate=0.05,
            num_leaves=63,
            min_child_samples=10,
            random_state=random_state,
        )
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ë° ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ë‹¨ì¼)")
    else:
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

st.markdown("---")

# --- 5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---
st.header("ğŸ“Š Step 5: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
with st.spinner("ì„±ëŠ¥ì„ í‰ê°€ ì¤‘..."):
    st.subheader("ğŸ“ˆ ë‹¨ì¼ ëª¨ë¸ ì„±ëŠ¥ (ê²€ì¦ ì„¸íŠ¸)")
    y_pred = rf_max.predict(X_max_test)
    st.session_state.mae_max = mean_absolute_error(y_max_test, y_pred)
    st.session_state.r2_max = r2_score(y_max_test, y_pred)
    
    # ê°€ìŠ¤ìˆ˜ìš” ë‹¨ì¼ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    if hasattr(st.session_state, 'gas_model') and hasattr(st.session_state, 'X_gas_test'):
        y_gas_pred = st.session_state.gas_model.predict(st.session_state.X_gas_test)
        st.session_state.mae_gas = mean_absolute_error(st.session_state.y_gas_test, y_gas_pred)
        st.session_state.r2_gas = r2_score(st.session_state.y_gas_test, y_gas_pred)

# ì„±ëŠ¥ ê²°ê³¼ í‘œì‹œ (ìµœëŒ€ìˆ˜ìš” / ê°€ìŠ¤ìˆ˜ìš” ë‚˜ë€íˆ)
if hasattr(st.session_state, 'mae_gas') and hasattr(st.session_state, 'r2_gas'):
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
        st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_max:,.0f} MW")
        st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_max:.4f}")
    with col2:
        st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
        st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_gas:,.0f} MW")
        st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_gas:.4f}")
else:
    st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
    st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_max:,.0f} MW")
    st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_max:.4f}")

# ê·¸ë˜í”„ ë¹„í‘œì‹œ(ìš”ì²­ì— ë”°ë¼ ê²€ì¦ ë¼ì¸ì°¨íŠ¸ ìƒëµ)

st.markdown("---")

# --- 6. ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ---
st.header("ğŸ”® Step 6: ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡")
st.info("ìš”ì¼ê³¼ ì²´ê°ì˜¨ë„ë¥¼ ì…ë ¥í•˜ê³  ì˜ˆì¸¡ ê¸°ê°„ì„ ì„ íƒí•˜ì—¬ ìµœëŒ€ìˆ˜ìš”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ì˜ˆì¸¡ ì…ë ¥ í¼
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ“ ì˜ˆì¸¡ ì¡°ê±´ ì…ë ¥")
    
    # ìš”ì¼ ì„ íƒ
    weekday_options = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
    selected_weekday = st.selectbox("ìš”ì¼ ì„ íƒ", weekday_options, index=0)
    
    # ì²´ê°ì˜¨ë„ ì…ë ¥ (ì—¬ë¦„/ê²¨ìš¸ ì ìš©)
    feels_like_simple = st.number_input("ì²´ê°ì˜¨ë„ (Â°C)", min_value=-50.0, max_value=50.0, value=20.0, step=0.1)
    
    # ì›” ì„ íƒ (ê³„ì ˆì„± ê³ ë ¤)
    month_options = list(range(1, 13))
    selected_month = st.selectbox("ì›” ì„ íƒ", month_options, index=4)  # 5ì›” ê¸°ë³¸ê°’
    
    # ì˜ˆì¸¡ ê¸°ê°„ì€ 1ì¼ë¡œ ê³ ì •
    horizon = 1
    # ì˜ˆì¸¡ ë²„íŠ¼
    predict_button = st.button("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰", type="primary")

with col2:
    st.subheader("ğŸ“Š ì…ë ¥ ì •ë³´")
    st.write(f"**ì„ íƒëœ ìš”ì¼:** {selected_weekday}")
    st.write(f"**ì²´ê°ì˜¨ë„:** {feels_like_simple}Â°C")
    st.write(f"**ì„ íƒëœ ì›”:** {selected_month}ì›”")

# ì˜ˆì¸¡ ì‹¤í–‰
if predict_button:
    try:
        with st.spinner("ì˜ˆì¸¡ì„ ìˆ˜í–‰ ì¤‘..."):
            # í‰ì¼/ì£¼ë§ + ìš”ì¼ ë”ë¯¸ êµ¬ì„± (ì˜ˆì¸¡ ì…ë ¥)
            weekday_dummies = {}
            # í‰ì¼/íœ´ì¼ íŒë‹¨: ìš”ì¼ ê¸°ë°˜(ì›”~ê¸ˆ=í‰ì¼). ì¶”í›„ UIë¡œ ì§ì ‘ ì„ íƒ ê°€ëŠ¥
            is_weekday = 1 if selected_weekday in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼'] else 0
            weekday_dummies['í‰ì¼_í‰ì¼'] = is_weekday
            weekday_dummies.update({f'ìš”ì¼_{w}': (1 if w == selected_weekday else 0) for w in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']})
            
            # ê³„ì ˆ íŒë³„
            is_summer_sel = selected_month in [5, 6, 7, 8, 9]
            is_winter_sel = selected_month in [10, 11, 12, 1, 2, 3, 4]

            # ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì§• ìƒì„± (ì—¬ë¦„: ì²´ê°ì˜¨ë„, ê·¸ ì™¸: ì²´ê°ì˜¨ë„ ëŒ€ìš©)
            est_high = feels_like_simple
            # ëª¨ë¸ ì„ íƒ(ë‹¨ì¼ ëª¨ë¸)
            model_max = rf_max
            
            def predict_one_day(feels_like_val: float, month_val: int, weekday_name: str, min_temp_val=None, max_temp_val=None) -> float:
                dummies = {'í‰ì¼_í‰ì¼': 1 if weekday_name in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼'] else 0}
                dummies.update({f'ìš”ì¼_{w}': (1 if w == weekday_name else 0) for w in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']})
                feats = {
                    # ëƒ‰ë°©ê°•ë„/ë‚œë°©ê°•ë„ ê³„ì‚°
                    'ëƒ‰ë°©ê°•ë„': max(0.0, (feels_like_val if max_temp_val is None else max_temp_val) - 25.0),
                    'ë‚œë°©ê°•ë„': max(0.0, 10.0 - (min_temp_val if min_temp_val is not None else feels_like_val)),
                    'ì›”': month_val,
                    # ê³„ì ˆë³„ ì¶”ê°€ ì˜¨ë„: ì—¬ë¦„=ìµœê³ ê¸°ì˜¨, ê²¨ìš¸=ìµœì €ê¸°ì˜¨
                    'ìµœê³ ê¸°ì˜¨': (max_temp_val if max_temp_val is not None else feels_like_val) if month_val in [5,6,7,8,9] else 0.0,
                    'ìµœì €ê¸°ì˜¨': (min_temp_val if min_temp_val is not None else feels_like_val) if month_val in [10,11,12,1,2,3,4] else 0.0,
                    'ì²´ê°ì˜¨ë„': feels_like_val,
                    'ì¼êµì°¨': ( (max_temp_val - min_temp_val) if (max_temp_val is not None and min_temp_val is not None) else 0.0 ),
                }
                feats.update(dummies)
                frame = pd.DataFrame([feats])
                # í›ˆë ¨ í”¼ì²˜ ì§‘í•©ê³¼ ì •ë ¬/ë³´ì •
                frame = align_features_for_model(model_max, frame)
                return float(model_max.predict(frame)[0])

            # ë‹¨ì¼ì¼ ì˜ˆì¸¡ ë˜ëŠ” ì¬ê·€ 7ì¼ ì˜ˆì¸¡
            if horizon == 1:
                predicted_max = predict_one_day(feels_like_simple, selected_month, selected_weekday)
                forecast_series = [predicted_max]
            else:
                # 7ì¼ ì¬ê·€ ì˜ˆì¸¡: ë§¤ ìŠ¤í…ì—ì„œ ë˜ê·¸/í‰ê·  ì—…ë°ì´íŠ¸
                weekday_cycle = ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']
                start_idx = weekday_cycle.index(selected_weekday)
                # ì‹œë“œ ì‹œê³„ì—´ ì¤€ë¹„
                tail = st.session_state.get('max_series_tail', [])
                buf = list(tail)
                if len(buf) < 14:
                    buf = ([buf[0]] * (14 - len(buf)) + buf) if buf else [0.0]*14
                forecast_series = []
                dyn_work = dyn.copy()
                for step in range(7):
                    wd_name = weekday_cycle[(start_idx + step) % 7]
                    y_hat = predict_one_day(feels_like_simple, selected_month, wd_name, dyn_work)
                    forecast_series.append(y_hat)
                    # ë²„í¼ ì—…ë°ì´íŠ¸ (ìµœëŒ€ 14ê°œ ìœ ì§€)
                    buf.append(y_hat)
                    if len(buf) > 14:
                        buf.pop(0)
                    # ë™ì  íŠ¹ì§• ì—…ë°ì´íŠ¸
                    dyn_work['ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”'] = buf[-1]
                    dyn_work['7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”'] = float(pd.Series(buf[-7:]).mean())
                    dyn_work['14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”'] = float(pd.Series(buf[-14:]).mean())
                    dyn_work['ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = buf[-7] if len(buf) >= 7 else dyn_work.get('ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”', 0.0)
                predicted_max = forecast_series[0]
            
            st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
            
            # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            st.subheader("ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼")
            
            if horizon == 1:
                st.metric("ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”", f"{predicted_max:,.0f} MW")
            else:
                st.write("**ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”(7ì¼):**")
                st.dataframe(pd.DataFrame({
                    'ì¼ì°¨': list(range(1, len(forecast_series)+1)),
                    'ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”': [f"{v:,.0f}" for v in forecast_series]
                }), use_container_width=True)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ì •ë³´
            st.subheader("ğŸ“‹ ì˜ˆì¸¡ ìƒì„¸ ì •ë³´")
            base_items = ['ìš”ì¼', 'ì²´ê°ì˜¨ë„', 'ì›”']
            base_vals = [selected_weekday, f"{feels_like_simple}Â°C", f"{selected_month}ì›”"]
            if horizon == 1:
                base_items.append('ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”')
                base_vals.append(f"{predicted_max:,.0f} MW")
            else:
                base_items.append('ì˜ˆì¸¡ ê¸°ê°„')
                base_vals.append(f"{horizon}ì¼")
            prediction_info = pd.DataFrame({'í•­ëª©': base_items, 'ê°’': base_vals})
            st.dataframe(prediction_info, use_container_width=True)
            
            # ì˜ˆì¸¡ ì‹ ë¢°ë„ (ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜)
            confidence_max = min(95, max(60, st.session_state.r2_max * 100))
            
            st.subheader("ğŸ“Š ì˜ˆì¸¡ ì‹ ë¢°ë„")
            st.metric("ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{confidence_max:.1f}%")
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            st.subheader("ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”")
            
            fig_prediction = go.Figure()
            
            # ìµœëŒ€ìˆ˜ìš”ë§Œ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ í‘œì‹œ
            fig_prediction.add_trace(go.Bar(
                x=['ìµœëŒ€ìˆ˜ìš”'],
                y=[predicted_max],
                name='ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”',
                marker_color=['red']
            ))
            
            fig_prediction.update_layout(
                title=f"{selected_weekday} (ì²´ê° {feels_like_simple}Â°C) ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡",
                yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
                showlegend=True
            )
            
            st.plotly_chart(fig_prediction, use_container_width=True)
            
    except Exception as e:
        st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì…ë ¥ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- ìƒˆë¡œìš´ ì˜ˆì¸¡ ê¸°ëŠ¥: ìµœì €ê¸°ì˜¨/ìµœê³ ê¸°ì˜¨ ì…ë ¥ ---
st.markdown("---")
st.subheader("ğŸŒ¡ï¸ ìƒì„¸ ê¸°ì˜¨ ê¸°ë°˜ ì˜ˆì¸¡")
st.info("ìµœì €ê¸°ì˜¨, ìµœê³ ê¸°ì˜¨, ì²´ê°ì˜¨ë„ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì—¬ ë” ì •í™•í•œ ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

# ìƒˆë¡œìš´ ì˜ˆì¸¡ ì…ë ¥ í¼
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ“ ìƒì„¸ ì˜ˆì¸¡ ì¡°ê±´ ì…ë ¥")
    
    # ìš”ì¼ ì„ íƒ (ìƒì„¸)
    selected_weekday_detailed = st.selectbox("ìš”ì¼ ì„ íƒ", ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼'], index=0, key="weekday_detailed")
    
    # ìµœì €ê¸°ì˜¨ ì…ë ¥
    min_temp = st.number_input("ìµœì €ê¸°ì˜¨ (Â°C)", min_value=-50.0, max_value=50.0, value=15.0, step=0.1, key="min_temp")
    
    # ìµœê³ ê¸°ì˜¨ ì…ë ¥
    max_temp = st.number_input("ìµœê³ ê¸°ì˜¨ (Â°C)", min_value=-50.0, max_value=50.0, value=25.0, step=0.1, key="max_temp")
    
    # ì²´ê°ì˜¨ë„ ì…ë ¥
    feels_like_detailed = st.number_input("ì²´ê°ì˜¨ë„ (Â°C)", min_value=-50.0, max_value=50.0, value=(min_temp + max_temp) / 2, step=0.1, key="feels_like_detailed")

    # ì›” ì„ íƒ (ê³„ì ˆì„± ê³ ë ¤)
    selected_month_detailed = st.selectbox("ì›” ì„ íƒ", month_options, index=4, key="month_detailed")  # 5ì›” ê¸°ë³¸ê°’
    
    # ìƒì„¸ ì˜ˆì¸¡ ë²„íŠ¼
    predict_detailed_button = st.button("ğŸ”® ìƒì„¸ ì˜ˆì¸¡ ì‹¤í–‰", type="primary", key="predict_detailed")

with col2:
    st.subheader("ğŸ“Š ìƒì„¸ ì…ë ¥ ì •ë³´")
    st.write(f"**ì„ íƒëœ ìš”ì¼:** {selected_weekday_detailed}")
    st.write(f"**ìµœì €ê¸°ì˜¨:** {min_temp}Â°C")
    st.write(f"**ìµœê³ ê¸°ì˜¨:** {max_temp}Â°C")
    st.write(f"**ì²´ê°ì˜¨ë„:** {feels_like_detailed}Â°C")

    st.write(f"**ì„ íƒëœ ì›”:** {selected_month_detailed}ì›”")

# ìƒì„¸ ì˜ˆì¸¡ ì‹¤í–‰
if predict_detailed_button:
    try:
        with st.spinner("ìƒì„¸ ì˜ˆì¸¡ì„ ìˆ˜í–‰ ì¤‘..."):

            
            # í‰ì¼/ì£¼ë§ + ìš”ì¼ ë”ë¯¸ êµ¬ì„± (ìƒì„¸ ì˜ˆì¸¡ ì…ë ¥)
            weekday_dummies_detailed = {}
            # í‰ì¼/íœ´ì¼ íŒë‹¨: ìš”ì¼ ê¸°ë°˜
            is_weekday_detailed = 1 if selected_weekday_detailed in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼'] else 0
            weekday_dummies_detailed['í‰ì¼_í‰ì¼'] = is_weekday_detailed
            weekday_dummies_detailed.update({f'ìš”ì¼_{w}': (1 if w == selected_weekday_detailed else 0) for w in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']})
            
            # ê³„ì ˆ íŒë³„
            is_summer_detailed = selected_month_detailed in [5, 6, 7, 8, 9]
            is_winter_detailed = selected_month_detailed in [10, 11, 12, 1, 2, 3, 4]

            # ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì§• ìƒì„± (ì—¬ë¦„: ì²´ê°ì˜¨ë„, ê·¸ ì™¸: ì‹¤ì œ ìµœê³ ê¸°ì˜¨)
            dyn = st.session_state.get('dynamic_max_features', {})
            max_features_detailed = {
                # ëƒ‰ë°©/ë‚œë°© ê°•ë„ ì‚¬ìš©
                'ëƒ‰ë°©ê°•ë„': max(0.0, max_temp - 25.0),
                'ë‚œë°©ê°•ë„': max(0.0, 10.0 - min_temp),
                'ì›”': selected_month_detailed,
                'ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”': dyn.get('ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”', 0.0),
                '7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”': dyn.get('7ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”', 0.0),
                '14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”': dyn.get('14ì¼í‰ê· _ìµœëŒ€ìˆ˜ìš”', 0.0),
                'ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”': dyn.get('ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”', 0.0),
                # ê³„ì ˆë³„ ì¶”ê°€ ì˜¨ë„: ì—¬ë¦„=ìµœê³ ê¸°ì˜¨ í¬í•¨, ê²¨ìš¸=ìµœì €ê¸°ì˜¨ í¬í•¨
                'ìµœê³ ê¸°ì˜¨': max_temp if is_summer_detailed else 0.0,
                'ìµœì €ê¸°ì˜¨': min_temp if is_winter_detailed else 0.0,
                'ì²´ê°ì˜¨ë„': feels_like_detailed,
                'ì¼êµì°¨': max_temp - min_temp,
            }
            max_features_detailed.update(weekday_dummies_detailed)
            
            # ë‹¨ì¼ ëª¨ë¸ ì„ íƒ í›„ í”¼ì²˜ ì •ë ¬/ë³´ì •
            model_max_detailed = rf_max
            max_input_detailed = pd.DataFrame([max_features_detailed])
            max_input_detailed = align_features_for_model(model_max_detailed, max_input_detailed)
            
            # ì˜ˆì¸¡ ì‹¤í–‰
            predicted_max_detailed = model_max_detailed.predict(max_input_detailed)[0]
            
            st.success("âœ… ìƒì„¸ ì˜ˆì¸¡ ì™„ë£Œ!")
            
            # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            st.subheader("ğŸ¯ ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼")
            
            st.metric("ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”", f"{predicted_max_detailed:,.0f} MW")
            
            # ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ì •ë³´
            st.subheader("ğŸ“‹ ìƒì„¸ ì˜ˆì¸¡ ìƒì„¸ ì •ë³´")
            prediction_info_detailed = pd.DataFrame({
                'í•­ëª©': ['ìš”ì¼', 'ìµœì €ê¸°ì˜¨', 'ìµœê³ ê¸°ì˜¨', 'ì²´ê°ì˜¨ë„', 'ì›”', 'ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”'],
                'ê°’': [selected_weekday_detailed, f"{min_temp}Â°C", f"{max_temp}Â°C", f"{feels_like_detailed:.1f}Â°C", f"{selected_month_detailed}ì›”", 
                      f"{predicted_max_detailed:,.0f} MW"]
            })
            st.dataframe(prediction_info_detailed, use_container_width=True)
            
            # ì˜ˆì¸¡ ì‹ ë¢°ë„ (ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜)
            confidence_max_detailed = min(95, max(60, st.session_state.r2_max * 100))
            
            st.subheader("ğŸ“Š ìƒì„¸ ì˜ˆì¸¡ ì‹ ë¢°ë„")
            st.metric("ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{confidence_max_detailed:.1f}%")
            
            # ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            st.subheader("ğŸ“ˆ ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”")
            
            fig_prediction_detailed = go.Figure()
            
            # ìµœëŒ€ìˆ˜ìš”ë§Œ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ í‘œì‹œ
            fig_prediction_detailed.add_trace(go.Bar(
                x=['ìµœëŒ€ìˆ˜ìš”'],
                y=[predicted_max_detailed],
                name='ìƒì„¸ ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”',
                marker_color=['red']
            ))
            
            fig_prediction_detailed.update_layout(
                title=f"{selected_weekday_detailed} (ìµœì €:{min_temp}Â°C, ìµœê³ :{max_temp}Â°C) ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡",
                yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
                showlegend=True
            )
            
            st.plotly_chart(fig_prediction_detailed, use_container_width=True)
            

            
    except Exception as e:
        st.error(f"âŒ ìƒì„¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì…ë ¥ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì„¹ì…˜ ---
st.markdown("---")
st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡")
st.info("ìµœëŒ€ìˆ˜ìš”ì™€ íƒœì–‘ê´‘ìµœëŒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ìŠ¤ìˆ˜ìš”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
if hasattr(st.session_state, 'gas_model'):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì¡°ê±´ ì…ë ¥")
        
        # ìš”ì¼ ì„ íƒ (í‰ì¼/ì£¼ë§ ë°˜ì˜)
        gas_weekday = st.selectbox("ìš”ì¼ ì„ íƒ", ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'], index=0, key="gas_weekday")
        gas_is_weekday = 1 if gas_weekday in ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼'] else 0

        # ìµœëŒ€ìˆ˜ìš” ì…ë ¥
        max_demand_input = st.number_input(
            "ìµœëŒ€ìˆ˜ìš” (MW)",
            min_value=0.0,
            max_value=100000.0,
            value=50000.0,
            step=1000.0
        )
        
        # íƒœì–‘ê´‘ìµœëŒ€ ì…ë ¥
        solar_max_input = st.number_input(
            "íƒœì–‘ê´‘ìµœëŒ€ (MW)",
            min_value=0.0,
            max_value=100000.0,
            value=50000.0,
            step=1000.0
        )
        
        # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ë²„íŠ¼
        predict_gas_button = st.button("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡", type="primary")
    
    with col2:
        st.subheader("ğŸ“Š ê°€ìŠ¤ìˆ˜ìš” ì…ë ¥ ì •ë³´")
        st.write(f"**ìš”ì¼:** {gas_weekday} ({'í‰ì¼' if gas_is_weekday else 'ì£¼ë§'})")
        st.write(f"**ìµœëŒ€ìˆ˜ìš”:** {max_demand_input:,.0f} MW")
        st.write(f"**íƒœì–‘ê´‘ìµœëŒ€:** {solar_max_input:,.0f} MW")
    
    # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì‹¤í–‰
    if predict_gas_button:
        try:
            with st.spinner("ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìˆ˜í–‰ ì¤‘..."):
                # ì˜ˆì¸¡ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŠ¹ì§•ê³¼ ì •í•©)
                last_gas = st.session_state.get('last_gas', None)
                prev_gas = st.session_state.get('prev_gas', None)

                # ë³€í™”ìœ¨ ê³„ì‚° (ê°€ëŠ¥í•˜ë©´), ë¶ˆê°€ ì‹œ 0.0
                if last_gas is not None and prev_gas is not None and prev_gas != 0:
                    gas_rate = (last_gas - prev_gas) / prev_gas
                else:
                    gas_rate = 0.0

                # ì…ë ¥ ê¸°ë°˜ íŒŒìƒ
                residual_load_input = max_demand_input - solar_max_input
                denom_total = max_demand_input if max_demand_input != 0 else 1.0
                solar_ratio_total = solar_max_input / denom_total
                residual_ratio_total = residual_load_input / denom_total

                # ì•ˆì „í•œ ê°€ìŠ¤/íƒœì–‘ê´‘ ë¹„ìœ¨ (ìµœê·¼ ê°€ìŠ¤ê°€ ì—†ë‹¤ë©´ 0)
                # í•„ìš” ì—†ëŠ” íŒŒìƒ ì œê±°: íƒœì–‘ê´‘_ê°€ìŠ¤_ë¹„ìœ¨ ì‚¬ìš© ì•ˆ í•¨

                # ì˜ˆì¸¡ ì…ë ¥ì„ í•™ìŠµ íŠ¹ì§•ì— ë§ì¶° êµ¬ì„± (ëˆ„ë½ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›€)
                input_dict = {f: 0.0 for f in st.session_state.features_gas}
                input_dict.update({
                    'ìµœëŒ€ìˆ˜ìš”': max_demand_input,
                    'íƒœì–‘ê´‘ìµœëŒ€': solar_max_input,
                    'ì”ì—¬ë¶€í•˜': residual_load_input,
                    'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨': solar_ratio_total,
                    'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨': residual_ratio_total,
                    'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°': max_demand_input * (st.session_state.get('gas_total_ratio_weekday', 0.0) if gas_is_weekday else st.session_state.get('gas_total_ratio_weekend', 0.0)) - solar_max_input,
                    'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”': last_gas if last_gas is not None else 0.0,
                    'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨': gas_rate,
                    'í‰ì¼_í‰ì¼': float(gas_is_weekday),
                })

                prediction_input_gas = pd.DataFrame([input_dict])
                
                # Step 5ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì˜ íŠ¹ì§• ë³€ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤
                if hasattr(st.session_state, 'features_gas'):
                    prediction_input_gas = prediction_input_gas[st.session_state.features_gas]
                    
                    # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ (ë‹¨ì¼ ëª¨ë¸)
                    predicted_gas_demand = st.session_state.gas_model.predict(prediction_input_gas)[0]
                    # ë¬¼ë¦¬ì  í´ë¦¬í•‘: 0 â‰¤ ê°€ìŠ¤ â‰¤ ìµœëŒ€ìˆ˜ìš”
                    predicted_gas_demand = max(0.0, min(predicted_gas_demand, max_demand_input))
                    
                    st.success("âœ… ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì™„ë£Œ!")
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
                    st.subheader("ğŸ“Š ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì…ë ¥ ìµœëŒ€ìˆ˜ìš”", f"{max_demand_input:,.0f} MW")
                    with col2:
                        st.metric("ì…ë ¥ íƒœì–‘ê´‘ìµœëŒ€", f"{solar_max_input:,.0f} MW")
                    with col3:
                        st.metric("ì˜ˆì¸¡ ê°€ìŠ¤ìˆ˜ìš”", f"{predicted_gas_demand:,.0f} MW")
                    
                    # ì˜ˆì¸¡ ì‹ ë¢°ë„
                    confidence_gas = min(95, max(60, st.session_state.r2_gas * 100)) if hasattr(st.session_state, 'r2_gas') else 60
                    st.metric("ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{confidence_gas:.1f}%")
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
                    st.subheader("ğŸ“ˆ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì‹œê°í™”")
                    
                    fig_prediction_gas = go.Figure()
                    
                    fig_prediction_gas.add_trace(go.Bar(
                        x=['ìµœëŒ€ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€', 'ì˜ˆì¸¡ ê°€ìŠ¤ìˆ˜ìš”'],
                        y=[max_demand_input, solar_max_input, predicted_gas_demand],
                        name='ì…ë ¥ê°’ ë° ì˜ˆì¸¡ê°’',
                        marker_color=['red', 'orange', 'green']
                    ))
                    
                    fig_prediction_gas.update_layout(
                        title="ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼",
                        yaxis_title="ê°’ (MW)",
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_prediction_gas, use_container_width=True)
                    
                    # ì˜ˆì¸¡ ê·¼ê±° ì„¤ëª…
                    st.subheader("ğŸ“‹ ì˜ˆì¸¡ ê·¼ê±°")
                    # ëª¨ë¸ ì¤‘ìš”ë„
                    feature_importance = st.session_state.gas_model.feature_importances_
                    
                    # Step 5ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì˜ ì‹¤ì œ íŠ¹ì§• ë³€ìˆ˜ ì‚¬ìš©
                    if hasattr(st.session_state, 'features_gas'):
                        if feature_importance is not None:
                            importance_df = pd.DataFrame({
                                'íŠ¹ì„±': st.session_state.features_gas,
                                'ì¤‘ìš”ë„': feature_importance
                            }).sort_values('ì¤‘ìš”ë„', ascending=False)
                            st.info(f"ğŸ’¡ ì£¼ìš” ì˜í–¥ ìš”ì¸: {importance_df.iloc[0]['íŠ¹ì„±']} ({importance_df.iloc[0]['ì¤‘ìš”ë„']:.1%})")
                            if len(importance_df) > 1:
                                st.info(f"ğŸ’¡ ë³´ì¡° ì˜í–¥ ìš”ì¸: {importance_df.iloc[1]['íŠ¹ì„±']} ({importance_df.iloc[1]['ì¤‘ìš”ë„']:.1%})")
                    else:
                        st.info("ğŸ’¡ ëª¨ë¸ì˜ íŠ¹ì§• ì¤‘ìš”ë„ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                else:
                    st.error("âŒ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            st.error(f"âŒ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì…ë ¥ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown("---")

# --- 7. ê´€ë ¨ ë§í¬ ---
st.header("ğŸ”— ê´€ë ¨ ë§í¬")
st.info("ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ê²€ì¦ì— ì‚¬ìš©ìˆ˜ ìˆëŠ” ë°ì´í„° ì†ŒìŠ¤ì…ë‹ˆë‹¤.")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸŒ¤ï¸ ê¸°ìƒì²­ ê¸°ìƒìë£Œê°œë°©í¬í„¸")
    st.write("ê¸°ì˜¨, ìŠµë„ ë“± ê¸°ìƒ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    st.markdown(
        "[ê¸°ìƒì²­ ê¸°ìƒìë£Œê°œë°©í¬í„¸ ë°”ë¡œê°€ê¸°](https://data.kma.go.kr/stcs/grnd/grndTaList.do?pgmNo=70)",
        help="ê¸°ìƒì²­ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ìƒ ê´€ì¸¡ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

with col2:
    st.subheader("âš¡ í•œêµ­ì „ë ¥ê±°ë˜ì†Œ")
    st.write("ì‹¤ì‹œê°„ ì „ë ¥ ìˆ˜ìš” ë° ê³µê¸‰ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.markdown(
        "[í•œêµ­ì „ë ¥ê±°ë˜ì†Œ ë°”ë¡œê°€ê¸°](https://www.kpx.or.kr/powerinfoSubmain.es?mid=a10606030000)",
        help="í•œêµ­ì „ë ¥ê±°ë˜ì†Œì—ì„œ ì œê³µí•˜ëŠ” ì „ë ¥ ìˆ˜ìš” ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

st.markdown("---")
