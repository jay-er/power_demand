import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from lightgbm import LGBMRegressor
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional, Dict, Any
import io
import gspread
from google.oauth2.service_account import Credentials
import os
import json
from functools import partial
import holidays

# ì„±ëŠ¥ ê´€ë ¨ ìƒìˆ˜
APPLY_SHEET_FORMATTING = False  # êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ì„œì‹ ì ìš© ì—¬ë¶€ (ì†ë„ ê°œì„ ì„ ìœ„í•´ ê¸°ë³¸ ë¹„í™œì„±í™”)
QUICK_SHEET_CONNECT = True      # êµ¬ê¸€ì‹œíŠ¸ ì—°ê²° ì‹œ ê²€ì¦ í˜¸ì¶œ ìƒëµí•˜ì—¬ ì´ˆê¸° ë¡œë”© ê°€ì†

# í•™ìŠµ ìºì‹± í•¨ìˆ˜ë“¤
@st.cache_resource(show_spinner=False)
def train_rf_model(X: pd.DataFrame, y: pd.Series, *, n_estimators: int, random_state: int) -> RandomForestRegressor:
    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state, n_jobs=-1)
    model.fit(X, y)
    return model

def tune_rf_model(
    X: pd.DataFrame,
    y: pd.Series,
    *,
    random_state: int,
):
    """ê°„ë‹¨í•œ ì‹œê³„ì—´ CV ê¸°ë°˜ RandomForest íŠœë‹."""
    # ì‹œê³„ì—´ ë¶„í•  (ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ì‹œê°„ ìˆœì„œë¡œ ê°€ì •)
    tscv = TimeSeriesSplit(n_splits=3)
    param_distributions = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 8, 12, 16],
        'min_samples_leaf': [1, 2, 4],
    }
    base = RandomForestRegressor(random_state=random_state, n_jobs=-1)
    search = RandomizedSearchCV(
        estimator=base,
        param_distributions=param_distributions,
        n_iter=6,
        scoring='neg_mean_absolute_error',
        cv=tscv,
        random_state=random_state,
        n_jobs=-1,
        verbose=0,
    )
    search.fit(X, y)
    return search.best_estimator_

def chronological_split(
    X: pd.DataFrame,
    y: pd.Series,
    dates: pd.Series,
    *,
    test_size: float,
):
    """ì‹œê°„ ìˆœì„œ(ì˜¤ë¦„ì°¨ìˆœ)ë¡œ í•™ìŠµ/í‰ê°€ ì„¸íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.

    ë§ˆì§€ë§‰ test_size ë¹„ìœ¨ êµ¬ê°„ì„ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # ì •ë ¬ìš© ì¸ë±ìŠ¤
        sort_idx = dates.sort_values().index
        X_sorted = X.loc[sort_idx]
        y_sorted = y.loc[sort_idx]
        split_idx = int(len(X_sorted) * (1 - test_size))
        split_idx = max(1, min(split_idx, len(X_sorted) - 1))
        return (
            X_sorted.iloc[:split_idx],
            X_sorted.iloc[split_idx:],
            y_sorted.iloc[:split_idx],
            y_sorted.iloc[split_idx:],
        )
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ì „ì²´ë¥¼ í•™ìŠµìœ¼ë¡œ ë°˜í™˜
        return X, X.iloc[0:0], y, y.iloc[0:0]

def align_features_for_model(model, df: pd.DataFrame) -> pd.DataFrame:
    """ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì»¬ëŸ¼ ì§‘í•©(feature_names_in_)ì— ì…ë ¥ì„ ì •ë ¬.
    - í•™ìŠµ ì‹œ ìˆì—ˆë˜ ì»¬ëŸ¼ì´ ì˜ˆì¸¡ ì‹œ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ìƒì„±
    - í•™ìŠµ ì‹œ ì—†ë˜ ì»¬ëŸ¼ì€ ë“œë¡­
    - ì»¬ëŸ¼ ìˆœì„œ ì¼ì¹˜
    """
    try:
        feature_names = list(getattr(model, 'feature_names_in_', []))
        if feature_names:
            for col in feature_names:
                if col not in df.columns:
                    df[col] = 0.0
            # ì—¬ë¶„ ì»¬ëŸ¼ ì œê±° ë° ìˆœì„œ ì •ë ¬
            df = df[feature_names]
    except Exception:
        pass
    return df

@st.cache_resource(show_spinner=False)
def train_lgbm_gas_model(
    X: pd.DataFrame,
    y: pd.Series,
    *,
    monotone_constraints: list,
    n_estimators: int,
    learning_rate: float,
    num_leaves: int,
    min_child_samples: int,
    random_state: int
):
    # ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§Œ ìºì‹œ í‚¤ì— ë°˜ì˜í•˜ë„ë¡ ì¸ì ìœ ì§€
    model = LGBMRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        num_leaves=num_leaves,
        min_child_samples=min_child_samples,
        random_state=random_state,
        n_jobs=-1,
        monotone_constraints=monotone_constraints,
    )
    model.fit(X, y)
    return model

# í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ì–´ì—¬ì•¼ í•¨)
st.set_page_config(
    page_title="ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
    page_icon="âš¡",
    layout="wide"
)

# ì œëª©
st.title("âš¡ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("---")
# ì „ì—­ ìŠ¤í”¼ë„ˆ í”Œë ˆì´ìŠ¤í™€ë” (ëª¨ë¸ í•™ìŠµ ì‹œ ìƒë‹¨ì—ë§Œ í‘œì‹œ)
train_spinner = st.empty()

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'mae_max' not in st.session_state:
    st.session_state.mae_max = None
if 'r2_max' not in st.session_state:
    st.session_state.r2_max = None

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
@st.cache_resource(show_spinner=False)
def setup_google_sheets():
    """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •"""
    try:
        # êµ¬ê¸€ ì‹œíŠ¸ API ìŠ¤ì½”í”„ ì„¤ì •
        scope = [
            'https://spreadsheets.google.com/feeds',
            'https://www.googleapis.com/auth/drive'
        ]
        
        # ë°©ë²• 1: Streamlit secretsì—ì„œ JSON í‚¤ ì½ê¸° (ìš°ì„ ìˆœìœ„)
        try:
            google_credentials_json = st.secrets.get('GOOGLE_CREDENTIALS_JSON')
            if google_credentials_json:
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸(ì˜µì…˜)
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: power-supply@flash-zenith-453703-p6.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì„ í¸ì§‘ìë¡œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
            else:
                st.warning("âš ï¸ Streamlit secretsì—ì„œ GOOGLE_CREDENTIALS_JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ Streamlit secrets ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
        
        # ë°©ë²• 2: ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ì½ê¸° (ëŒ€ì•ˆ)
        new_key_file = 'new-service-account-key.json'
        
        if os.path.exists(new_key_file):
            try:
                # JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
                with open(new_key_file, 'r', encoding='utf-8') as f:
                    credentials_data = json.load(f)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: ìƒˆë¡œìš´_ì„œë¹„ìŠ¤_ê³„ì •_ì´ë©”ì¼@test-92f50.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì„ í¸ì§‘ìë¡œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
            except Exception as e:
                st.error(f"âŒ ìƒˆë¡œìš´ í‚¤ íŒŒì¼ ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                return None
            except Exception as e:
                st.error(f"âŒ ìƒˆë¡œìš´ í‚¤ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                return None
        
        # ë°©ë²• 2: í™˜ê²½ë³€ìˆ˜ì—ì„œ JSON í‚¤ ì½ê¸° (ëŒ€ì•ˆ)
        google_credentials_json = os.getenv('GOOGLE_CREDENTIALS_JSON')
        
        if google_credentials_json:
            try:
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                if not QUICK_SHEET_CONNECT:
                    try:
                        test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                        return client
                    except Exception as test_error:
                        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                        st.info("""
                        **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                        1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: firebase-adminsdk-fbsvc@test-92f50.iam.gserviceaccount.com
                        2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                        3. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— í¸ì§‘ì ê¶Œí•œìœ¼ë¡œ ê³µìœ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        """)
                        return None
                return client
                    
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                st.info("í™˜ê²½ë³€ìˆ˜ GOOGLE_CREDENTIALS_JSONì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            except Exception as e:
                st.error(f"âŒ ì¸ì¦ ì •ë³´ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                st.info("""
                **PEM íŒŒì¼ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:**
                1. private_keyì˜ ê°œí–‰ ë¬¸ì í™•ì¸
                2. JSON í‚¤ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
                3. ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ í™•ì¸
                4. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
                """)
                return None
        
        # ë°©ë²• 2: Streamlit secretsì—ì„œ JSON í‚¤ ì½ê¸° (ë°±ì—…)
        if hasattr(st, 'secrets') and 'GOOGLE_CREDENTIALS_JSON' in st.secrets:
            try:
                st.info("ğŸ” Streamlit secretsì—ì„œ ì¸ì¦ ì •ë³´ë¥¼ ì½ëŠ” ì¤‘...")
                google_credentials_json = st.secrets['GOOGLE_CREDENTIALS_JSON']
                
                # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                credentials_data = json.loads(google_credentials_json)
                
                # private_key í˜•ì‹ ê²€ì¦ ë° ìˆ˜ì •
                if 'private_key' in credentials_data:
                    private_key = credentials_data['private_key']
                    # ê°œí–‰ ë¬¸ì ì •ê·œí™”
                    if '\\n' in private_key:
                        credentials_data['private_key'] = private_key.replace('\\n', '\n')
                        st.info("âœ… private_key ê°œí–‰ ë¬¸ì ì •ê·œí™” ì™„ë£Œ")
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in credentials_data]
                if missing_fields:
                    st.error(f"âŒ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}")
                    return None
                
                st.info("ğŸ” ì¸ì¦ ì •ë³´ ìƒì„± ì¤‘...")
                
                # ì¸ì¦ ì •ë³´ ìƒì„±
                creds = Credentials.from_service_account_info(
                    credentials_data, 
                    scopes=scope
                )
                
                st.info("ğŸ” gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                st.info("ğŸ” êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
                try:
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì—°ê²° í™•ì¸
                    test_sheet = client.open_by_key("1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4")
                    st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ!")
                    return client
                except Exception as test_error:
                    st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(test_error)}")
                    st.info("""
                    **êµ¬ê¸€ ì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸:**
                    1. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼: firebase-adminsdk-fbsvc@test-92f50.iam.gserviceaccount.com
                    2. êµ¬ê¸€ ì‹œíŠ¸ ID: 1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4
                    3. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— í¸ì§‘ì ê¶Œí•œìœ¼ë¡œ ê³µìœ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    """)
                    return None
                    
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                st.info("Streamlit secretsì˜ GOOGLE_CREDENTIALS_JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            except Exception as e:
                st.error(f"âŒ Streamlit secrets ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                return None
        
        # ë°©ë²• 3: JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
        json_file_path = "test-92f50-a704ebe1984f.json"
        if os.path.exists(json_file_path):
            try:
                st.info(f"ğŸ” JSON íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ë¥¼ ì½ëŠ” ì¤‘: {json_file_path}")
                
                creds = Credentials.from_service_account_file(
                    json_file_path,
                    scopes=scope
                )
                
                # gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = gspread.authorize(creds)
                return client
            except Exception as e:
                st.error(f"âŒ JSON íŒŒì¼ ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
                st.info(f"íŒŒì¼ ê²½ë¡œ: {json_file_path}")
                return None
        
        # ë°©ë²• 4: ê¸°ë³¸ ì¸ì¦ ì •ë³´ ì‚¬ìš© (ê°œë°œìš©)
        st.warning("âš ï¸ í™˜ê²½ë³€ìˆ˜, Streamlit secrets, JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("""
        **êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì • ë°©ë²•:**
        
        1. **í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¶Œì¥):**
           - GOOGLE_CREDENTIALS_JSON í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        
        2. **Streamlit secrets ì„¤ì •:**
           - .streamlit/secrets.toml íŒŒì¼ì— GOOGLE_CREDENTIALS_JSON ì„¤ì •
        
        3. **JSON íŒŒì¼ ì‚¬ìš©:**
           - test-92f50-a704ebe1984f.json íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸
        
        4. **ì„œë¹„ìŠ¤ ê³„ì • ì„¤ì •:**
           - êµ¬ê¸€ í´ë¼ìš°ë“œ ì½˜ì†”ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ìƒì„±
           - êµ¬ê¸€ ì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ ê³µìœ 
        """)
        
        # ê°œë°œìš© ë”ë¯¸ í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì‹¤ì œ ì—°ê²°ì€ ì•ˆë¨)
        return None
            
    except Exception as e:
        st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        st.info("""
        **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:**
        1. JSON í‚¤ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
        2. ì„œë¹„ìŠ¤ ê³„ì •ì´ êµ¬ê¸€ ì‹œíŠ¸ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸
        3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
        4. private_keyì˜ ê°œí–‰ ë¬¸ì í˜•ì‹ í™•ì¸
        """)
        return None

def load_data_from_sheet(client, sheet_name="power_data", sheet_id=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ (ë¹„ìºì‹œ ì›ë³¸)"""
    try:
        # ì‹œíŠ¸ ì—´ê¸° (IDê°€ ì œê³µëœ ê²½ìš° IDë¡œ, ì•„ë‹ˆë©´ ì´ë¦„ìœ¼ë¡œ)
        if sheet_id and sheet_id.strip():
            sheet = client.open_by_key(sheet_id).sheet1
        else:
            sheet = client.open(sheet_name).sheet1
        
        # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_values = sheet.get_all_values()
        
        if len(all_values) == 0:
            st.error("âŒ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
        headers = all_values[0]
        data_rows = all_values[1:]
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(data_rows, columns=headers)
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
        numeric_columns = ['ìµœê³ ê¸°ì˜¨', 'í‰ê· ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ìµœëŒ€ìˆ˜ìš”', 'ì²´ê°ì˜¨ë„']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ë‚ ì§œ ì»¬ëŸ¼ì„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
        if 'ë‚ ì§œ' in df.columns:
            try:
                # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
                df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
            except Exception as e:
                st.warning(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return df
    except Exception as e:
        st.error(f"âŒ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

@st.cache_data(show_spinner=False, ttl=300)
def load_data_from_sheet_cached(sheet_name="power_data", sheet_id=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ (ìºì‹œ) - 5ë¶„ TTL"""
    client = setup_google_sheets()
    if client is None:
        return None
    return load_data_from_sheet(client, sheet_name, sheet_id)

def save_data_to_sheet(client, data, sheet_name="power_data", sheet_id=None, original_data=None):
    """êµ¬ê¸€ ì‹œíŠ¸ì— ë°ì´í„° ì €ì¥ (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)"""
    try:
        # ì‹œíŠ¸ ì—´ê¸° (IDê°€ ì œê³µëœ ê²½ìš° IDë¡œ, ì•„ë‹ˆë©´ ì´ë¦„ìœ¼ë¡œ)
        if sheet_id and sheet_id.strip():
            sheet = client.open_by_key(sheet_id).sheet1
        else:
            sheet = client.open(sheet_name).sheet1
        
        # ì›” ì»¬ëŸ¼ ì œê±° (ë‚´ë¶€ ê³„ì‚°ìš©ì´ë¯€ë¡œ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•˜ì§€ ì•ŠìŒ)
        data_to_save = data.copy()
        if 'ì›”' in data_to_save.columns:
            data_to_save = data_to_save.drop(columns=['ì›”'])
        
        # ì›ë³¸ ë°ì´í„°ë„ ì›” ì»¬ëŸ¼ ì œê±°í•˜ì—¬ ë¹„êµ
        original_data_to_compare = None
        if original_data is not None:
            original_data_to_compare = original_data.copy()
            if 'ì›”' in original_data_to_compare.columns:
                original_data_to_compare = original_data_to_compare.drop(columns=['ì›”'])
        
        # ì›ë³¸ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš° ë³€ê²½ëœ ë¶€ë¶„ë§Œ ê°ì§€
        if original_data_to_compare is not None:
            # ë³€ê²½ëœ í–‰ê³¼ ì—´ ê°ì§€
            changed_rows = []
            changed_columns = []
            
            # ë°ì´í„° íƒ€ì… í†µì¼ì„ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
            data_str = data_to_save.astype(str)
            original_str = original_data_to_compare.astype(str)
            
            # ë³€ê²½ëœ í–‰ ê°ì§€
            for idx in range(len(data_to_save)):
                if idx < len(original_str) and not data_str.iloc[idx].equals(original_str.iloc[idx]):
                    changed_rows.append(idx + 2)  # +2ëŠ” í—¤ë”(1)ì™€ 0-based ì¸ë±ìŠ¤(1) ë•Œë¬¸
            
            # ë³€ê²½ëœ ì—´ ê°ì§€
            for col in data_to_save.columns:
                if col in original_str.columns and not data_str[col].equals(original_str[col]):
                    changed_columns.append(col)
            
            # ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸ (ìµœì í™”ëœ ë°°ì¹˜ ë°©ì‹)
            if changed_rows:
                # ë³€ê²½ëœ í–‰ë“¤ì„ í•˜ë‚˜ì˜ ì—°ì†ëœ ë²”ìœ„ë¡œ ê·¸ë£¹í™”
                changed_rows.sort()  # í–‰ ë²ˆí˜¸ ì •ë ¬
                
                # ì—°ì†ëœ í–‰ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                row_groups = []
                current_group = [changed_rows[0]]
                
                for i in range(1, len(changed_rows)):
                    if changed_rows[i] == changed_rows[i-1] + 1:
                        # ì—°ì†ëœ í–‰
                        current_group.append(changed_rows[i])
                    else:
                        # ë¶ˆì—°ì†ëœ í–‰ - ìƒˆ ê·¸ë£¹ ì‹œì‘
                        row_groups.append(current_group)
                        current_group = [changed_rows[i]]
                
                row_groups.append(current_group)  # ë§ˆì§€ë§‰ ê·¸ë£¹ ì¶”ê°€
                
                # ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ ë²”ìœ„ë¡œ ì—…ë°ì´íŠ¸
                for group in row_groups:
                    start_row = group[0]
                    end_row = group[-1]
                    
                    # í•´ë‹¹ ë²”ìœ„ì˜ ë°ì´í„° ì¶”ì¶œ
                    group_data = data_to_save.iloc[start_row-2:end_row-1]  # -2ëŠ” ì¸ë±ìŠ¤ ì¡°ì •
                    
                    # ê° í–‰ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    group_values = []
                    for _, row in group_data.iterrows():
                        row_values = []
                        for val in row:
                            if pd.isna(val):
                                row_values.append('')
                            elif isinstance(val, pd.Timestamp):
                                row_values.append(val.strftime('%Y-%m-%d'))
                            elif isinstance(val, str) and 'T' in val:
                                try:
                                    date_obj = pd.to_datetime(val)
                                    row_values.append(date_obj.strftime('%Y-%m-%d'))
                                except:
                                    row_values.append(str(val))
                            else:
                                row_values.append(str(val))
                        group_values.append(row_values)
                    
                    # ë²”ìœ„ ì—…ë°ì´íŠ¸ (ì—°ì†ëœ í–‰ë“¤ì„ í•œ ë²ˆì—)
                    range_name = f'A{start_row}:{chr(65 + len(group_values[0]) - 1)}{end_row}'
                    
                    # ì„œì‹ ë³µì‚¬: ë°”ë¡œ ìœ„ í–‰ì˜ ì„œì‹ì„ ë”°ë¼ê°€ë„ë¡ ì„¤ì •
                    try:
                        if APPLY_SHEET_FORMATTING and start_row > 2:  # ì˜µì…˜: ì„œì‹ ì ìš©
                            format_range = f'A{start_row}:{chr(65 + len(group_values[0]) - 1)}{end_row}'
                            sheet.format(format_range, {
                                "textFormat": {
                                    "fontSize": 11,
                                    "fontFamily": "Arial"
                                }
                            })
                    except Exception as e:
                        st.warning(f"âš ï¸ ì„œì‹ ì ìš© ì‹¤íŒ¨: {str(e)}")
                    
                    # ë°ì´í„° ì—…ë°ì´íŠ¸
                    # ë¹ ë¥¸ ì—…ë°ì´íŠ¸(ë°°ì¹˜) ëª¨ë“œ
                    sheet.update(range_name, group_values, value_input_option='RAW')
                
                return True, f"âœ… {len(changed_rows)}ê°œ í–‰ì´ {len(row_groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        # ì›ë³¸ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì „ì²´ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°
        # ë‚ ì§œ ì»¬ëŸ¼ì„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
        for col in data_to_save.columns:
            if data_to_save[col].dtype == 'datetime64[ns]':
                data_to_save[col] = data_to_save[col].dt.strftime('%Y-%m-%d')
            elif data_to_save[col].dtype == 'object':
                # ë¬¸ìì—´ ì»¬ëŸ¼ì—ì„œ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸
                try:
                    # ì²« ë²ˆì§¸ ìœ íš¨í•œ ê°’ìœ¼ë¡œ ë‚ ì§œ í˜•ì‹ í™•ì¸
                    first_valid = data_to_save[col].dropna().iloc[0] if len(data_to_save[col].dropna()) > 0 else None
                    if first_valid and isinstance(first_valid, str) and ('T' in first_valid or '-' in first_valid):
                        # ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œë„
                        data_to_save[col] = pd.to_datetime(data_to_save[col], errors='coerce').dt.strftime('%Y-%m-%d')
                except:
                    pass  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
        
        # ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì—…ë°ì´íŠ¸ (API í˜¸ì¶œ ìµœì†Œí™”)
        all_values = [data_to_save.columns.tolist()]  # í—¤ë”
        for _, row in data_to_save.iterrows():
            # ê° ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            row_values = [str(val) if val is not None else '' for val in row.tolist()]
            all_values.append(row_values)
        
        # ì‹œíŠ¸ë¥¼ í•œ ë²ˆì— ì—…ë°ì´íŠ¸
        sheet.clear()
        sheet.update('A1', all_values, value_input_option='RAW')
        
        return True, "âœ… ì „ì²´ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        st.error(f"âŒ ì‹œíŠ¸ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False, f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}"

# ì‚¬ì´ë“œë°” ì œê±°ë¨ (ìš”ì²­ì— ë”°ë¼ ë¹„í‘œì‹œ)

# ì „ì—­ ë¡œë”© ìƒíƒœ í‘œì‹œ í”Œë ˆì´ìŠ¤í™€ë” (Step 0 ìœ„)
global_status_placeholder = st.empty()

# --- 0. ë°ì´í„° ë¡œë”© ë° í¸ì§‘ ---
st.header("ğŸ“ Step 0: ë°ì´í„° ë¡œë”© ë° í¸ì§‘")

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
st.subheader("ğŸ” êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •")

client = setup_google_sheets()
if client is None:
    st.warning("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì´ ì¼ì‹œì ìœ¼ë¡œ ì§€ì—°ë©ë‹ˆë‹¤. ìºì‹œëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì • ì •ë³´
sheet_name = "ì‹œíŠ¸1"
sheet_id = "1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4"

# ìµœì‹  ë°ì´í„° ê°•ì œ ê°±ì‹  ë²„íŠ¼ (ìºì‹œ/ì„¸ì…˜ ì´ˆê¸°í™” í›„ ì¦‰ì‹œ ì¬ì¡°íšŒ)
refresh_col1, refresh_col2 = st.columns([1, 3])
with refresh_col1:
    if st.button("ğŸ”„ ìµœì‹  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="secondary"):
        try:
            st.cache_data.clear()
        except Exception:
            pass
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”(ë°ì´í„° ë° ì˜ì¡´ ìƒíƒœ)
        for k in [
            'data', 'original_data',
            'dynamic_max_features', 'max_series_tail',
            'last_gas', 'prev_gas',
        ]:
            st.session_state.pop(k, None)
        # ë¹„ìºì‹œ ë¡œë”© ìš°ì„  ì‹œë„
        with st.spinner("ìµœì‹  ë°ì´í„° ë¡œë”© ì¤‘..."):
            fresh = None
            if client is not None:
                fresh = load_data_from_sheet(client, sheet_name, sheet_id)
            if fresh is None:
                fresh = load_data_from_sheet_cached(sheet_name, sheet_id)
            if fresh is not None:
                st.session_state.data = fresh
                st.session_state.original_data = fresh.copy()
                st.success("âœ… ìµœì‹  ë°ì´í„°ë¡œ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.error("âŒ ìµœì‹  ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ë°ì´í„° ìë™ ë¡œë”© (ìºì‹œ ìš°ì„ )
if 'data' not in st.session_state:
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        data = load_data_from_sheet_cached(sheet_name, sheet_id)
        if data is None and client is not None:
            data = load_data_from_sheet(client, sheet_name, sheet_id)
        if data is not None:
            st.session_state.data = data
            st.session_state.original_data = data.copy()
        else:
            st.error("âŒ ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

# ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
if 'data' not in st.session_state:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

data = st.session_state.data

# ë°ì´í„° í¸ì§‘ ê¸°ëŠ¥
st.subheader("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° í¸ì§‘")

# ë°ì´í„° ì •ë³´ í‘œì‹œ
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ì´ í–‰ ìˆ˜", f"{len(data):,}ê°œ")
with col2:
    st.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{len(data.columns)}ê°œ")
with col3:
    # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
    if 'ë‚ ì§œ' in data.columns:
        try:
            # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            date_data = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
            start_date = date_data.min().strftime('%Y-%m-%d')
        except (ValueError, TypeError) as e:
            st.warning(f"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            start_date = "N/A"
    else:
        start_date = "N/A"
    st.metric("ì‹œì‘ì¼", start_date)
with col4:
    if 'ë‚ ì§œ' in data.columns:
        try:
            date_data = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
            end_date = date_data.max().strftime('%Y-%m-%d')
        except (ValueError, TypeError) as e:
            st.warning(f"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            end_date = "N/A"
    else:
        end_date = "N/A"
    st.metric("ì¢…ë£Œì¼", end_date)

# ë°ì´í„° í¸ì§‘ íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", "âœï¸ ë°ì´í„° í¸ì§‘", "ğŸ“ˆ í†µê³„ ì •ë³´"])

with tab1:
    st.subheader("ì „ì²´ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    
    # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ë³€í™˜
    display_data = data.copy()
    if 'ë‚ ì§œ' in display_data.columns:
        try:
            # datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
            display_data['ë‚ ì§œ'] = pd.to_datetime(display_data['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
        except Exception as e:
            st.warning(f"ë‚ ì§œ í‘œì‹œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
    
    st.dataframe(display_data, use_container_width=True)
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    csv = data.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ë°ì´í„°ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="power_data_edited.csv",
        mime="text/csv"
    )

with tab2:
    st.subheader("ë°ì´í„° í¸ì§‘")
    st.info("ì•„ë˜ì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ í¸ì§‘í•˜ê±°ë‚˜ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í¸ì§‘ í›„ 'ë³€ê²½ì‚¬í•­ ì ìš©' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    # í¸ì§‘ìš© ë°ì´í„° ì¤€ë¹„ (ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì„± í™•ë³´)
    if 'edit_data' not in st.session_state:
        # ì²˜ìŒ ë¡œë“œí•  ë•Œë§Œ í¸ì§‘ìš© ë°ì´í„° ì¤€ë¹„
        edit_data = data.copy()
        
        # ì›” ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±° (ë‚´ë¶€ ê³„ì‚°ìš©ì´ë¯€ë¡œ í¸ì§‘ ë¶ˆê°€)
        if 'ì›”' in edit_data.columns:
            edit_data = edit_data.drop(columns=['ì›”'])
        
        if 'ë‚ ì§œ' in edit_data.columns:
            try:
                # datetimeìœ¼ë¡œ ë³€í™˜ í›„ ë…„ì›”ì¼ê¹Œì§€ë§Œ í‘œì‹œ
                edit_data['ë‚ ì§œ'] = pd.to_datetime(edit_data['ë‚ ì§œ'], errors='coerce').dt.strftime('%Y-%m-%d')
            except Exception as e:
                st.warning(f"ë‚ ì§œ í¸ì§‘ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.edit_data = edit_data
    else:
        # ì„¸ì…˜ ìƒíƒœì—ì„œ í¸ì§‘ìš© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        edit_data = st.session_state.edit_data
    
    # í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„
    edited_data = st.data_editor(
        edit_data,
        num_rows="dynamic",
        use_container_width=True,
        key="data_editor"
    )
    
    # ë³€ê²½ì‚¬í•­ ì ìš© ë²„íŠ¼
    if st.button("âœ… ë³€ê²½ì‚¬í•­ ì ìš©", type="primary"):
        with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì¤‘... (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)"):
            # í¸ì§‘ëœ ë°ì´í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ì— ë°˜ì˜
            data = edited_data.copy()
            
            # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ (í¸ì§‘ ì‹œ ë¬¸ìì—´ë¡œ í‘œì‹œë˜ì—ˆìœ¼ë¯€ë¡œ)
            if 'ë‚ ì§œ' in data.columns:
                try:
                    data['ë‚ ì§œ'] = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
                except Exception as e:
                    st.warning(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ì›” ì»¬ëŸ¼ ë‹¤ì‹œ ì¶”ê°€ (ë‚´ë¶€ ê³„ì‚°ìš©)
            if 'ë‚ ì§œ' in data.columns:
                try:
                    # ë‚ ì§œì—ì„œ ì›” ì¶”ì¶œí•˜ì—¬ ì›” ì»¬ëŸ¼ ì¶”ê°€
                    data['ì›”'] = pd.to_datetime(data['ë‚ ì§œ']).dt.month
                except Exception as e:
                    st.warning(f"ì›” ì»¬ëŸ¼ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            
            st.session_state.data = data
            
            # í¸ì§‘ìš© ë°ì´í„° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë‹¤ìŒ í¸ì§‘ì„ ìœ„í•´)
            if 'edit_data' in st.session_state:
                del st.session_state.edit_data
            
            # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ì— ì €ì¥ëœ ì›ë³¸ ë°ì´í„°)
            original_data = st.session_state.get('original_data', None)
            
            # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸)
            success, message = save_data_to_sheet(client, data, sheet_name, sheet_id, original_data)
            
            if success:
                st.success(message)
                
                # ì›ë³¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë‹¤ìŒ í¸ì§‘ì„ ìœ„í•´)
                st.session_state.original_data = data.copy()
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.data_updated = True
                st.rerun()
            else:
                st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ API í•œë„ ì´ˆê³¼ë¡œ ì¸í•œ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        csv_updated = data.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=csv_updated,
            file_name="power_data_updated.csv",
            mime="text/csv"
        )
        
        # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì˜µì…˜
        st.subheader("ğŸ’¾ ì—‘ì…€ íŒŒì¼ ì €ì¥")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“Š ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥", type="secondary"):
                try:
                    # ì„ì‹œ ì—‘ì…€ íŒŒì¼ ìƒì„±
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        data.to_excel(writer, index=False, sheet_name='Power_Data')
                    
                    excel_buffer.seek(0)
                    st.download_button(
                        label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=excel_buffer.getvalue(),
                        file_name="power_data_updated.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    st.success("âœ… ì—‘ì…€ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"âŒ ì—‘ì…€ íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        with col2:
            st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ê°€ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤!")
    
    # ì›ë³¸ êµ¬ê¸€ì‹œíŠ¸ ì£¼ì†Œ
    st.subheader("ğŸ“Š ì›ë³¸ êµ¬ê¸€ì‹œíŠ¸")
    st.markdown("[ğŸ”— ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ë°ì´í„° ë°”ë¡œ ê°€ê¸°](https://docs.google.com/spreadsheets/d/1xyL8hCNBtf7Xo5jyIFEdoNoVJWEMSkgxMZ4nUywSBH4/edit?gid=0#gid=0)")

with tab3:
    st.subheader("ë°ì´í„° í†µê³„ ì •ë³´")
    
    # ìˆ˜ì¹˜í˜• ë°ì´í„° í†µê³„
    numeric_cols = data.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        st.write("**ìˆ˜ì¹˜í˜• ë°ì´í„° í†µê³„:**")
        st.dataframe(data[numeric_cols].describe(), use_container_width=True)
    
    # ë²”ì£¼í˜• ë°ì´í„° í†µê³„
    categorical_cols = data.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        st.write("**ë²”ì£¼í˜• ë°ì´í„° í†µê³„:**")
        for col in categorical_cols:
            st.write(f"**{col}:**")
            value_counts = data[col].value_counts()
            st.dataframe(value_counts, use_container_width=True)
    
    # ê²°ì¸¡ê°’ ì •ë³´
    missing_data = data.isnull().sum()
    if missing_data.sum() > 0:
        st.write("**ê²°ì¸¡ê°’ ì •ë³´:**")
        st.dataframe(missing_data[missing_data > 0], use_container_width=True)
    else:
        st.success("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!")

st.markdown("---")

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
with st.expander("ğŸ“‹ Step 1: ë°ì´í„° ì¤€ë¹„", expanded=False):
    with st.spinner("ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ì¤‘..."):
        # NOTE: ì‹¤ì œ ì „ì²˜ë¦¬ ì½”ë“œëŠ” ì•„ë˜ì— ìˆìœ¼ë©°, êµ¬ë¬¸ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë³¸ ë¸”ë¡ì— ìµœì†Œ ë³¸ë¬¸ì„ ë‘¡ë‹ˆë‹¤.
        pass
    # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    if 'ë‚ ì§œ' in data.columns:
        data['ë‚ ì§œ'] = pd.to_datetime(data['ë‚ ì§œ'])
    else:
        st.error("âŒ 'ë‚ ì§œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ìš”ì¼/í‰ì¼/ê³µíœ´ì¼/ì—…ë¬´ì¼ íŒŒìƒ (ì—†ìœ¼ë©´ ìƒì„±)
    try:
        weekday_map = {0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'}
        if 'ìš”ì¼' not in data.columns:
            data['ìš”ì¼'] = data['ë‚ ì§œ'].dt.weekday.map(weekday_map)
        # ê³µíœ´ì¼ í”Œë˜ê·¸ ìƒì„± (KR)
        try:
            kr_holidays = holidays.KR()
            data['ê³µíœ´ì¼'] = data['ë‚ ì§œ'].dt.date.apply(lambda x: 1 if x in kr_holidays else 0)
        except Exception:
            data['ê³µíœ´ì¼'] = 0
        # ì—…ë¬´ì¼: ê³µíœ´ì¼ì´ ì•„ë‹Œ í‰ì¼(ì›”~ê¸ˆ)
        data['ìš”ì¼ìˆ«ì'] = data['ë‚ ì§œ'].dt.weekday
        data['ì—…ë¬´ì¼'] = ((data['ìš”ì¼ìˆ«ì'] < 5) & (data['ê³µíœ´ì¼'] == 0)).astype(int)
        # ê¸°ì¡´ í‰ì¼ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì—…ë¬´ì¼ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
        if 'í‰ì¼' not in data.columns:
            data['í‰ì¼'] = np.where(data['ì—…ë¬´ì¼'] == 1, 'í‰ì¼', 'íœ´ì¼')
    except Exception:
        pass
    
    # êµ¬ê¸€ì‹œíŠ¸ì˜ 'í‰ì¼' ì»¬ëŸ¼ í‘œì¤€í™”: í‰ì¼/íœ´ì¼ë§Œ ë‚¨ê¸°ê³  ë™ì˜ì–´/ê³µë°±/ëŒ€ì†Œë¬¸ì ì •ê·œí™”
    try:
        if 'í‰ì¼' in data.columns:
            weekday_holiday_raw = data['í‰ì¼'].astype(str).str.strip().str.lower()
            normalization_map = {
                'í‰ì¼': 'í‰ì¼',
                'weekday': 'í‰ì¼',
                'ê·¼ë¬´ì¼': 'í‰ì¼',
                'íœ´ì¼': 'íœ´ì¼',
                'ì£¼ë§': 'íœ´ì¼',
                'ê³µíœ´ì¼': 'íœ´ì¼',
                'holiday': 'íœ´ì¼',
                'weekend': 'íœ´ì¼',
            }
            normalized = weekday_holiday_raw.map(normalization_map).fillna(weekday_holiday_raw)
            # ìµœì¢…ì ìœ¼ë¡œ 'í‰ì¼' ë˜ëŠ” 'íœ´ì¼' ë‘ ê°’ë§Œ ìœ ì§€, ì´ì™¸ëŠ” ìš”ì¼ë¡œ ë³´ì •
            mask_unexpected = ~normalized.isin(['í‰ì¼', 'íœ´ì¼'])
            if mask_unexpected.any():
                normalized.loc[mask_unexpected] = np.where(
                    ((data.loc[mask_unexpected, 'ë‚ ì§œ'].dt.weekday < 5) & (data.loc[mask_unexpected, 'ê³µíœ´ì¼'] == 0)),
                    'í‰ì¼', 'íœ´ì¼'
                )
            data['í‰ì¼'] = normalized
    except Exception:
        pass
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
    required_columns = ['ìµœê³ ê¸°ì˜¨', 'í‰ê· ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ìµœëŒ€ìˆ˜ìš”', 'ì²´ê°ì˜¨ë„']  # 'í‰ì¼'ì€ ë‚´ë¶€ ê³„ì‚°ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥
    missing_columns = [col for col in required_columns if col not in data.columns]
    
    if missing_columns:
        st.warning(f"âš ï¸ ì¼ë¶€ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        st.info("ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆì–´ë„ ê°€ëŠ¥í•œ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤.")
        
        # ìµœì†Œí•œì˜ í•„ìˆ˜ ì»¬ëŸ¼ë§Œ í™•ì¸ (ìµœì €ìˆ˜ìš” ì œì™¸)
        essential_columns = ['ë‚ ì§œ', 'ìµœëŒ€ìˆ˜ìš”']
        essential_missing = [col for col in essential_columns if col not in data.columns]
        
        if essential_missing:
            st.error(f"âŒ í•µì‹¬ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {essential_missing}")
            st.info("ìµœì†Œí•œ ë‚ ì§œ, ìµœëŒ€ìˆ˜ìš” ì»¬ëŸ¼ì€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
    
    # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° í™•ì¸
    gas_columns = ['ê°€ìŠ¤ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€']
    available_gas_columns = [col for col in gas_columns if col in data.columns]
    
    if available_gas_columns:
        st.success(f"âœ… ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê°€ëŠ¥: {', '.join(available_gas_columns)} ì»¬ëŸ¼ ë°œê²¬")
        if len(available_gas_columns) == 2:
            st.info("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥")
        else:
            st.warning(f"âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•´ ì¶”ê°€ ì»¬ëŸ¼ í•„ìš”: {[col for col in gas_columns if col not in available_gas_columns]}")
    else:
        st.info("â„¹ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ (ê°€ìŠ¤ìˆ˜ìš”, íƒœì–‘ê´‘ìµœëŒ€)")
    
    # ë°ì´í„° ì •ë³´ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ë°ì´í„° ìˆ˜", f"{len(data):,}ê°œ")
    with col2:
        st.metric("ì‹œì‘ì¼", data['ë‚ ì§œ'].min().strftime('%Y-%m-%d'))
    with col3:
        st.metric("ì¢…ë£Œì¼", data['ë‚ ì§œ'].max().strftime('%Y-%m-%d'))

st.markdown("---")

# --- 2. íŠ¹ì§• ê³µí•™ ë° ë°ì´í„° ì •ì œ ---
with st.expander("ğŸ”§ Step 2: íŠ¹ì§• ê³µí•™ ë° ë°ì´í„° ì •ì œ", expanded=False):
    with st.spinner("íŠ¹ì§• ê³µí•™ì„ ìˆ˜í–‰ ì¤‘..."):
        # NOTE: ì‹¤ì œ íŠ¹ì§• ê³µí•™ ì½”ë“œëŠ” ì•„ë˜ì— ìˆìœ¼ë©°, êµ¬ë¬¸ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë³¸ ë¸”ë¡ì— ìµœì†Œ ë³¸ë¬¸ì„ ë‘¡ë‹ˆë‹¤.
        pass
    data['ì›”'] = data['ë‚ ì§œ'].dt.month
    data['ì¼'] = data['ë‚ ì§œ'].dt.day
    data['ì—°ë„'] = data['ë‚ ì§œ'].dt.year
    # ê³µíœ´ì¼ í”Œë˜ê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í‰ì¼ ì»¬ëŸ¼ 'í‰ì¼/íœ´ì¼'ì— í†µí•©)
    
    # ìš”ì¼ ë”ë¯¸ ìƒì„±(ëª¨ë“  ìš”ì¼ í¬í•¨)
    data_processed = pd.get_dummies(data, columns=['ìš”ì¼'], drop_first=False)
    try:
        # ê³µíœ´ì¼ í”Œë˜ê·¸ë„ ë³´ì¡´(ëª¨ë¸ ì…ë ¥ ì—¬ë¶€ëŠ” features_max êµ¬ì„±ì— ë”°ë¦„)
        data_processed['ê³µíœ´ì¼'] = data.get('ê³µíœ´ì¼', 0)
        # ì—…ë¬´ì¼ì€ ì´ë¯¸ dataì— ìƒì„±ë˜ì–´ ìˆìŒ
        if 'ì—…ë¬´ì¼' in data.columns:
            data_processed['ì—…ë¬´ì¼'] = data['ì—…ë¬´ì¼'].astype(int)
    except Exception:
        pass
    # ì–´ì œ ìˆ˜ìš” ë˜ê·¸ (t-1)
    try:
        data_processed['ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”'] = pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce').shift(1)
    except Exception:
        data_processed['ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”'] = 0.0
    
    # ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìƒì„± (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
    try:
        is_summer_mask = data_processed['ì›”'].isin([5, 6, 7, 8, 9])
        is_winter_mask = data_processed['ì›”'].isin([10, 11, 12, 1, 2, 3, 4])
        
        # ê°œì„ ëœ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§•: ëƒ‰ë°©ê°•ë„/ë‚œë°©ê°•ë„
        st.subheader("ğŸŒ¡ï¸ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìµœì í™”")
        cooling_base_temp = 25.0
        heating_base_temp = 10.0
        # ëƒ‰ë°©ê°•ë„: ì²´ê°ì˜¨ë„(ìˆìœ¼ë©´) ì—†ìœ¼ë©´ ìµœê³ ê¸°ì˜¨ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        if 'ì²´ê°ì˜¨ë„' in data_processed.columns:
            temp_for_cooling = data_processed['ì²´ê°ì˜¨ë„']
        elif 'ìµœê³ ê¸°ì˜¨' in data_processed.columns:
            temp_for_cooling = data_processed['ìµœê³ ê¸°ì˜¨']
        else:
            st.error("âŒ ì˜¨ë„ ê´€ë ¨ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œí•œ ìµœê³ ê¸°ì˜¨ ë˜ëŠ” ì²´ê°ì˜¨ë„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
        data_processed['ëƒ‰ë°©ê°•ë„'] = (pd.to_numeric(temp_for_cooling, errors='coerce') - cooling_base_temp).clip(lower=0)
        
        # ë‚œë°©ê°•ë„: ìµœì €ê¸°ì˜¨ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        if 'ìµœì €ê¸°ì˜¨' in data_processed.columns:
            temp_for_heating = pd.to_numeric(data_processed['ìµœì €ê¸°ì˜¨'], errors='coerce')
            data_processed['ë‚œë°©ê°•ë„'] = (heating_base_temp - temp_for_heating).clip(lower=0)
        else:
            st.warning("âš ï¸ ìµœì €ê¸°ì˜¨ì´ ì—†ì–´ ë‚œë°©ê°•ë„ëŠ” 0ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
            data_processed['ë‚œë°©ê°•ë„'] = 0.0
        st.success("âœ… ëƒ‰ë°©/ë‚œë°© ê°•ë„ë¥¼ ë°˜ì˜í•œ ê³„ì ˆë³„ ì˜¨ë„ íŠ¹ì§• ìƒì„± ì™„ë£Œ!")
        # ê³„ì ˆ ë§ˆìŠ¤í¬ ì ìš©: ì—¬ë¦„ì—” ëƒ‰ë°©ê°•ë„ë§Œ, ê²¨ìš¸ì—” ë‚œë°©ê°•ë„ë§Œ ì‚¬ìš©
        data_processed['ëƒ‰ë°©ê°•ë„'] = data_processed['ëƒ‰ë°©ê°•ë„'] * is_summer_mask.astype(int)
        data_processed['ë‚œë°©ê°•ë„'] = data_processed['ë‚œë°©ê°•ë„'] * is_winter_mask.astype(int)

        # ì¶”ê°€ ì˜¨ë„ íŒŒìƒ: ì¼êµì°¨(ìµœê³ -ìµœì €) (ê°€ëŠ¥í•  ë•Œ)
        try:
            if 'ìµœê³ ê¸°ì˜¨' in data_processed.columns and 'ìµœì €ê¸°ì˜¨' in data_processed.columns:
                data_processed['ì¼êµì°¨'] = pd.to_numeric(data_processed['ìµœê³ ê¸°ì˜¨'], errors='coerce') - pd.to_numeric(data_processed['ìµœì €ê¸°ì˜¨'], errors='coerce')
        except Exception:
            pass

        # ì´ë™í‰ê· (ëˆ„ìˆ˜ ë°©ì§€: shift(1) í›„ rolling)
        try:
            # 7ì¼í‰ê·  ì œê±° ìš”ì²­ìœ¼ë¡œ ìƒì„±í•˜ì§€ ì•ŠìŒ
            data_processed['ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = data_processed['ìµœëŒ€ìˆ˜ìš”'].shift(7)
            # ì‘ë…„ ë™ì¼ì›”ì˜ ê°™ì€ ìš”ì¼ í‰ê· ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš” ìƒì„±
            try:
                # ë¨¼ì € (ì „ë…„ë„) ì›”Ã—ìš”ì¼ í‰ê·  ë§µì„ ì¤€ë¹„í–ˆë‹¤ê³  ê°€ì •í•˜ê³ , ì—†ìœ¼ë©´ ì§€ê¸ˆ ìƒì„±
                ly_map = st.session_state.get('last_year_month_weekday_mean_max')
                if not ly_map:
                    if 'ì—°ë„' in data_processed.columns and 'ì›”' in data_processed.columns and 'ìš”ì¼' in data_processed.columns:
                        max_year = int(pd.to_numeric(data_processed['ì—°ë„'], errors='coerce').dropna().max())
                        target_year = max_year - 1
                        df_prev_year = data_processed[pd.to_numeric(data_processed['ì—°ë„'], errors='coerce') == target_year]
                        if len(df_prev_year) == 0:
                            df_prev_year = data_processed
                        grp = df_prev_year.groupby(['ì›”', 'ìš”ì¼'])['ìµœëŒ€ìˆ˜ìš”'].mean().reset_index()
                        ly_map = {(int(r['ì›”']), str(r['ìš”ì¼'])): float(r['ìµœëŒ€ìˆ˜ìš”']) for _, r in grp.iterrows()}
                        st.session_state.last_year_month_weekday_mean_max = ly_map
                    else:
                        ly_map = {}

                if ly_map and 'ì›”' in data_processed.columns and 'ìš”ì¼' in data_processed.columns:
                    data_processed['ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = [
                        float(ly_map.get((int(m), str(w)), 0.0)) for m, w in zip(data_processed['ì›”'], data_processed['ìš”ì¼'])
                    ]
                else:
                    data_processed['ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = 0.0
            except Exception:
                data_processed['ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”'] = 0.0
            # ì‘ë…„ ì›”-ìš”ì¼ í‰ê·  ë§µ(ì˜ˆì¸¡ ì‹œ ì‚¬ìš©í•  ë°±ì—…)
            try:
                # ê°€ì¥ ìµœê·¼ ì—°ë„ì˜ ì§ì „ ì—°ë„ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ìƒì„±
                if 'ì—°ë„' in data_processed.columns and 'ì›”' in data_processed.columns and 'ìš”ì¼' in data_processed.columns:
                    max_year = int(pd.to_numeric(data_processed['ì—°ë„'], errors='coerce').dropna().max())
                    target_year = max_year - 1
                    df_prev_year = data_processed[pd.to_numeric(data_processed['ì—°ë„'], errors='coerce') == target_year]
                    if len(df_prev_year) == 0:
                        df_prev_year = data_processed
                    grp = df_prev_year.groupby(['ì›”', 'ìš”ì¼'])['ìµœëŒ€ìˆ˜ìš”'].mean().reset_index()
                    ly_mw_map = {(int(r['ì›”']), str(r['ìš”ì¼'])): float(r['ìµœëŒ€ìˆ˜ìš”']) for _, r in grp.iterrows()}
                    st.session_state.last_year_month_weekday_mean_max = ly_mw_map
            except Exception:
                st.session_state.last_year_month_weekday_mean_max = {}
        except Exception:
            pass

        # ìµœì‹  ê´€ì¸¡ ê¸°ë°˜ ë™ì  ì…ë ¥ ê¸°ë³¸ê°’ ì €ì¥ (ì˜ˆì¸¡ ì‹œ ì‚¬ìš©)
        try:
            st.session_state.dynamic_max_features = {}
            # ì¬ê·€ ì˜ˆì¸¡ì„ ìœ„í•œ ìµœê·¼ 14ì¼ íƒ€ê¹ƒ ì‹œê³„ì—´ ì €ì¥
            try:
                st.session_state.max_series_tail = list(pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce').dropna().tail(14).values)
            except Exception:
                st.session_state.max_series_tail = []
        except Exception:
            st.session_state.dynamic_max_features = {}
            st.session_state.max_series_tail = []
            
    except Exception as e:
        st.error(f"âŒ ì˜¨ë„ íŠ¹ì§• ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()
    
    # ê°€ìŠ¤ìˆ˜ìš” íŠ¹ì§• ê³µí•™
    if 'ê°€ìŠ¤ìˆ˜ìš”' in data_processed.columns and 'íƒœì–‘ê´‘ìµœëŒ€' in data_processed.columns:
        # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜
        data_processed['ê°€ìŠ¤ìˆ˜ìš”'] = pd.to_numeric(data_processed['ê°€ìŠ¤ìˆ˜ìš”'], errors='coerce')
        data_processed['íƒœì–‘ê´‘ìµœëŒ€'] = pd.to_numeric(data_processed['íƒœì–‘ê´‘ìµœëŒ€'], errors='coerce')
        # ì”ì—¬ë¶€í•˜(ìµœëŒ€ìˆ˜ìš” - íƒœì–‘ê´‘ìµœëŒ€)
        if 'ìµœëŒ€ìˆ˜ìš”' in data_processed.columns:
            try:
                data_processed['ì”ì—¬ë¶€í•˜'] = pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce') - data_processed['íƒœì–‘ê´‘ìµœëŒ€']
            except Exception:
                pass
            # ìµœëŒ€ìˆ˜ìš” ëŒ€ë¹„ ë¹„ìœ¨ íŠ¹ì§•ë“¤ (ê°€ìŠ¤ ì œì™¸, ëˆ„ì„¤ ë°©ì§€)
            try:
                denom = data_processed['ìµœëŒ€ìˆ˜ìš”'].replace(0, np.nan)
                data_processed['ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨'] = (data_processed['íƒœì–‘ê´‘ìµœëŒ€'] / denom).fillna(0.0)
                data_processed['ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨'] = (data_processed['ì”ì—¬ë¶€í•˜'] / denom).fillna(0.0)
            except Exception:
                pass

        # (ê°€ìŠ¤+íƒœì–‘ê´‘)/ìµœëŒ€ìˆ˜ìš” ì´ë¹„ìœ¨ì˜ í‰ì¼/ì£¼ë§ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì˜ˆì‚°í˜• ê°€ìŠ¤ ê¸°ì¤€ì¹˜ ìƒì„±
        try:
            denom_total = data_processed['ìµœëŒ€ìˆ˜ìš”'].replace(0, np.nan)
            total_ratio = (data_processed['ê°€ìŠ¤ìˆ˜ìš”'] + data_processed['íƒœì–‘ê´‘ìµœëŒ€']) / denom_total
            # í‰ì¼ í”Œë˜ê·¸ íŒŒìƒ (ì›-í•«ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ì—ì„œ ìœ ë„)
            # í‰ì¼_í‰ì¼ ì œê±°: ì—…ë¬´ì¼(ê³µíœ´ì¼ ê³ ë ¤)ë¡œ ëŒ€ì²´
            if 'ì—…ë¬´ì¼' in data_processed.columns:
                is_weekday_series = data_processed['ì—…ë¬´ì¼']
            else:
                is_weekday_series = ((data['ë‚ ì§œ'].dt.weekday < 5) & (~data['ë‚ ì§œ'].dt.date.isin(holidays.KR()))).astype(int)

            weekday_mean = total_ratio[is_weekday_series == 1].mean()
            weekend_mean = total_ratio[is_weekday_series == 0].mean()
            global_mean = total_ratio.mean()

            if pd.isna(weekday_mean):
                weekday_mean = global_mean
            if pd.isna(weekend_mean):
                weekend_mean = global_mean

            # ì„¸ì…˜ì— ì €ì¥ (ì˜ˆì¸¡ ì‹œ ì‚¬ìš©)
            st.session_state.gas_total_ratio_weekday = float(weekday_mean) if not pd.isna(weekday_mean) else 0.0
            st.session_state.gas_total_ratio_weekend = float(weekend_mean) if not pd.isna(weekend_mean) else 0.0

            # í–‰ë³„ ì˜ˆì‚° ë¹„ìœ¨ ì„ íƒ í›„ ëª©í‘œ ê°€ìŠ¤ëŸ‰ ê³„ì‚°: max*ratio - solar
            ratio_used = np.where(is_weekday_series == 1, st.session_state.gas_total_ratio_weekday, st.session_state.gas_total_ratio_weekend)
            data_processed['ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°'] = (data_processed['ìµœëŒ€ìˆ˜ìš”'] * ratio_used - data_processed['íƒœì–‘ê´‘ìµœëŒ€']).clip(lower=0)
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ì»¬ëŸ¼ ë¯¸ìƒì„±
            pass
        
        # ê²°ì¸¡ê°’ ì œê±° í›„ íŠ¹ì§• ê³µí•™
        gas_data_clean = data_processed[['ê°€ìŠ¤ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€']].dropna()
        if len(gas_data_clean) > 0:
            data_processed['ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”'] = data_processed['ê°€ìŠ¤ìˆ˜ìš”'].shift(1)
            # ëˆ„ì„¤ ë°©ì§€: ë³€í™”ìœ¨ì€ tì‹œì ì´ ì•„ë‹ˆë¼ (t-1,t-2)ë¡œ ê³„ì‚°
            data_processed['ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨'] = data_processed['ê°€ìŠ¤ìˆ˜ìš”'].pct_change().shift(1)
            # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìµœì‹  ê´€ì¸¡ ë˜ê·¸ ë³´ê´€
            try:
                last_two_gas = pd.to_numeric(gas_data_clean['ê°€ìŠ¤ìˆ˜ìš”'], errors='coerce').dropna().tail(2).values
                if len(last_two_gas) >= 1:
                    st.session_state.last_gas = float(last_two_gas[-1])
                if len(last_two_gas) == 2:
                    st.session_state.prev_gas = float(last_two_gas[0])
            except Exception:
                pass
            st.success("âœ… ì „ë ¥ìˆ˜ìš” ë° ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
        else:
            st.warning("âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„°ê°€ ìˆ«ìë¡œ ë³€í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.success("âœ… ì „ë ¥ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
    else:
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ë°ì´í„° ì •ì œ ì™„ë£Œ!")
    
    # ìµœì†Œ í•µì‹¬ ì»¬ëŸ¼ë§Œ ì „ì—­ ê²°ì¸¡ ì œê±° (ë‚˜ë¨¸ì§€ëŠ” ëª¨ë¸ ì§ì „ì— ê°œë³„ ì •ì œ)
    essential_cols = ['ìµœëŒ€ìˆ˜ìš”', 'ì›”']
    essential_cols = [c for c in essential_cols if c in data_processed.columns]
    if len(essential_cols) > 0:
        data_processed.dropna(subset=essential_cols, inplace=True)
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ì •ë³´
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì •ì œ í›„ ë°ì´í„° ìˆ˜", f"{len(data_processed):,}ê°œ")
    with col2:
        st.metric("íŠ¹ì§• ë³€ìˆ˜ ìˆ˜", f"{len(data_processed.columns)}ê°œ")
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ” ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(data_processed.head(10), use_container_width=True)

st.markdown("---")

 # --- 3. ëª¨ë¸ ë³€ìˆ˜ ë° ë°ì´í„° ë¶„ë¦¬ ---
with st.expander("ğŸ¯ Step 3: ëª¨ë¸ ë³€ìˆ˜ ë° ë°ì´í„° ë¶„ë¦¬", expanded=False):
    # í‰ê· ê¸°ì˜¨ì„ ëª¨ë¸ íŠ¹ì§•ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í–¥í›„ í•„ìš” ì‹œ Trueë¡œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ ë³€ìˆ˜ë§Œ ìœ ì§€)
    include_avg_temp_feature = False

    # [ìµœëŒ€ìˆ˜ìš” ëª¨ë¸] (ì—¬ë¦„ì² ì—ëŠ” ì²´ê°ì˜¨ë„ ì‚¬ìš©)
    _base_max = ['ëƒ‰ë°©ê°•ë„', 'ë‚œë°©ê°•ë„', 'ì›”', 'ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”', 'ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”', 'ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”', 'ê³µíœ´ì¼', 'ì—…ë¬´ì¼']
    if include_avg_temp_feature:
        _base_max.insert(1, 'í‰ê· ê¸°ì˜¨')

    # ì¶”ê°€ë¡œ ìµœì €/ìµœê³ /ì²´ê°/ì¼êµì°¨ê¹Œì§€ í•¨ê»˜ ì‚¬ìš© (ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
    _temp_extras = [f for f in ['ìµœê³ ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ì²´ê°ì˜¨ë„', 'ì¼êµì°¨'] if f in data_processed.columns]

    # ìš”ì¼ ë”ë¯¸ í¬í•¨ (í‰ì¼_í‰ì¼ ì œê±°)
    _dummies = [col for col in data_processed if col.startswith('ìš”ì¼_')]

    features_max = _base_max + _temp_extras + _dummies

    # í•™ìŠµ ì§ì „ ê²°ì¸¡ ë³´ì •: ì–´ì œ/7ì¼í‰ê· /ì „ì£¼ë™ì¼ ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ NaNì¸ ê²½ìš° 0ìœ¼ë¡œ ëŒ€ì²´
    for lag_col in ['ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”', 'ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”', 'ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”']:
        if lag_col in data_processed.columns:
            data_processed[lag_col] = pd.to_numeric(data_processed[lag_col], errors='coerce').fillna(0)

    # ì˜¨ë„ ê´€ë ¨ í”¼ì²˜ ì¡´ì¬ ì‹œ ìˆ«ì ë³€í™˜ ë° ê²°ì¸¡ í—ˆìš©(ëª¨ë¸ì´ ë¶„í• ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ì˜í–¥ ì ìŒ)
    for temp_col in ['ìµœê³ ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ì²´ê°ì˜¨ë„', 'ì¼êµì°¨', 'ëƒ‰ë°©ê°•ë„', 'ë‚œë°©ê°•ë„']:
        if temp_col in data_processed.columns:
            data_processed[temp_col] = pd.to_numeric(data_processed[temp_col], errors='coerce')

    X_max = data_processed[features_max].copy()
    y_max = pd.to_numeric(data_processed['ìµœëŒ€ìˆ˜ìš”'], errors='coerce')

# X, y ë™ì‹œ ê²°ì¸¡ ì œê±°(í•„ìš” ìµœì†Œ ë²”ìœ„)
    valid_mask = ~y_max.isna()
    for c in X_max.columns:
        valid_mask &= ~X_max[c].isna()
    X_max = X_max[valid_mask]
    y_max = y_max[valid_mask]

# ìµœì €ìˆ˜ìš” ëª¨ë¸ ì œê±° - ìµœëŒ€ìˆ˜ìš” ëª¨ë¸ë§Œ ì‚¬ìš©

# ê³ ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
    test_size = 0.2
    n_estimators = 100
    random_state = 42

# ë‹¨ì¼ ëª¨ë¸ìš© ë°ì´í„° ë¶„í•  - ì‹œê°„ìˆœ ë¶„í•  (í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ì œê±°)
    X_max_train, X_max_test, y_max_train, y_max_test = chronological_split(
        X_max, y_max, pd.to_datetime(data.loc[X_max.index, 'ë‚ ì§œ'], errors='coerce'), test_size=test_size
    )

# ë³€ìˆ˜ ì •ë³´ í‘œì‹œ
    st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜")
    st.write(f"íŠ¹ì§• ë³€ìˆ˜: {len(features_max)}ê°œ")
    # í‘œì‹œìš© ì´ë¦„ ë§¤í•‘: 'ëƒ‰ë°©ê°•ë„'/'ë‚œë°©ê°•ë„'ë¥¼ ì§ê´€ì ìœ¼ë¡œ í‘œì‹œ
    _display_name_map = {
        'ëƒ‰ë°©ê°•ë„': 'ëƒ‰ë°©ê°•ë„(>25Â°C)',
        'ë‚œë°©ê°•ë„': 'ë‚œë°©ê°•ë„(<10Â°C)',
    }

# UI í‘œì‹œìš©ìœ¼ë¡œë§Œ ìš”ì¼ ë”ë¯¸ë¥¼ ì›”â†’ì¼ ìˆœì„œë¡œ ì¬ë°°ì¹˜
    weekday_display_order = [
        'ìš”ì¼_ì›”ìš”ì¼', 'ìš”ì¼_í™”ìš”ì¼', 'ìš”ì¼_ìˆ˜ìš”ì¼', 'ìš”ì¼_ëª©ìš”ì¼',
        'ìš”ì¼_ê¸ˆìš”ì¼', 'ìš”ì¼_í† ìš”ì¼', 'ìš”ì¼_ì¼ìš”ì¼'
    ]
    weekday_cols_present = [c for c in features_max if c.startswith('ìš”ì¼_')]
    weekday_cols_ordered = [c for c in weekday_display_order if c in weekday_cols_present]
    non_weekday_cols = [c for c in features_max if not c.startswith('ìš”ì¼_')]
    features_max_display_ordered = non_weekday_cols + weekday_cols_ordered

    display_features_max = [_display_name_map.get(name, name) for name in features_max_display_ordered]
    # í—¤ë” í–‰ì„ ì‚¬ìš©í•œ í•œ ì¤„ í‘œ
    max_vars_df = pd.DataFrame([display_features_max], columns=[f'ë³€ìˆ˜{i+1}' for i in range(len(display_features_max))])
    st.dataframe(max_vars_df, use_container_width=True)

    # ìš”ì¼ ë”ë¯¸ ê¸°ì¤€ ë²”ì£¼ ì•ˆë‚´ (drop_first=Trueë¡œ ì¸í•´ í‘œì—ì„œ ë¹ ì§„ ìš”ì¼)
    try:
        existing_weekday_dummy_cols = [c for c in data_processed.columns if c.startswith('ìš”ì¼_')]
        all_weekdays = ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']
        baseline_weekdays = [d for d in all_weekdays if f'ìš”ì¼_{d}' not in existing_weekday_dummy_cols]
        if len(baseline_weekdays) > 0:
            st.caption(f"ìš”ì¼ ì›-í•«ì€ ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ì¤€ ë²”ì£¼ê°€ 1ê°œ ë¹ ì§‘ë‹ˆë‹¤ (ê¸°ì¤€: {', '.join(baseline_weekdays)}). ëª¨ë¸ì—ëŠ” ê¸°ì¤€ ìš”ì¼ë„ ì •ìƒ ë°˜ì˜ë©ë‹ˆë‹¤.")
    except Exception:
        pass



    # ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜ (ê°€ëŠ¥í•œ ê²½ìš°)
    if 'ê°€ìŠ¤ìˆ˜ìš”' in data_processed.columns and 'íƒœì–‘ê´‘ìµœëŒ€' in data_processed.columns:
        st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ ë³€ìˆ˜")
        # ìµœì†ŒÂ·í•µì‹¬ í”¼ì²˜ ìœ„ì£¼ êµ¬ì„± (ë‹¤ì¤‘ê³µì„ ì„±/ëˆ„ì„¤ ìœ„í—˜ ë‚®ì¶¤)
        features_gas = [
        'ìµœëŒ€ìˆ˜ìš”',          # ì´ ìŠ¤ì¼€ì¼
        'íƒœì–‘ê´‘ìµœëŒ€',        # ëŒ€ì²´ê´€ê³„ í•µì‹¬
        'ì”ì—¬ë¶€í•˜',          # ì”ì—¬ ì´ëŸ‰
        'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨',
        'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨',
        'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°',      # í‰ì¼/ì£¼ë§ ì´ë¹„ìœ¨ ì˜ˆì‚°
        'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”',     # ë˜ê·¸
        'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨',# ë˜ê·¸ ë³€í™”ìœ¨(ëˆ„ì„¤ ë°©ì§€)
        'ì—…ë¬´ì¼'             # í‰ì¼/ì£¼ë§(ê³µíœ´ì¼ ê³ ë ¤) íš¨ê³¼
    ]
        available_gas_features = [col for col in features_gas if col in data_processed.columns]
    
        if len(available_gas_features) >= 2:  # ìµœì†Œ 2ê°œ ë³€ìˆ˜ í•„ìš”
            X_gas = data_processed[available_gas_features]
            y_gas = data_processed['ê°€ìŠ¤ìˆ˜ìš”']
        
        # ê°€ìŠ¤ìˆ˜ìš” ë°ì´í„° ë¶„í•  - ì‹œê°„ìˆœ ë¶„í•  (íƒœì–‘ê´‘ìµœëŒ€ëŠ” 2024-12-01 ì´í›„ ë°ì´í„°ë§Œ í•™ìŠµ ì‚¬ìš©)
            try:
                gas_date_series = pd.to_datetime(data_processed.loc[X_gas.index, 'ë‚ ì§œ'], errors='coerce')
                cutoff = pd.Timestamp('2024-12-01')
                mask_after_cutoff = gas_date_series >= cutoff
                X_gas = X_gas[mask_after_cutoff]
                y_gas = y_gas[mask_after_cutoff]
                gas_date_series = gas_date_series[mask_after_cutoff]
            except Exception:
                pass

            X_gas_train, X_gas_test, y_gas_train, y_gas_test = chronological_split(
                X_gas, y_gas, gas_date_series if 'gas_date_series' in locals() else data_processed.loc[X_gas.index, 'ë‚ ì§œ'], test_size=test_size
            )
        
            st.write(f"íŠ¹ì§• ë³€ìˆ˜: {len(available_gas_features)}ê°œ")
            gas_vars_df = pd.DataFrame([available_gas_features], columns=[f'ë³€ìˆ˜{i+1}' for i in range(len(available_gas_features))])
            st.dataframe(gas_vars_df, use_container_width=True)
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë‹¨ì¼ ì „ì²´ ì„¸íŠ¸)
        st.session_state.X_gas_train = X_gas_train
        st.session_state.X_gas_test = X_gas_test
        st.session_state.y_gas_train = y_gas_train
        st.session_state.y_gas_test = y_gas_test
        st.session_state.features_gas = available_gas_features

        # í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ì„¸íŠ¸ ìƒì„±
        if 'ì—…ë¬´ì¼' in data_processed.columns:
            try:
                mask_weekday = data_processed['ì—…ë¬´ì¼'] == 1
            except Exception:
                mask_weekday = pd.Series(False, index=data_processed.index)
        else:
            # ì›ë³¸ 'í‰ì¼'ì—ì„œ ìœ ë„
            mask_weekday = (data['í‰ì¼'] == 'í‰ì¼') if 'í‰ì¼' in data.columns else pd.Series(False, index=data_processed.index)

        try:
            X_gas_wd = X_gas[mask_weekday]
            y_gas_wd = y_gas[mask_weekday]
            X_gas_we = X_gas[~mask_weekday]
            y_gas_we = y_gas[~mask_weekday]

            # í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ì„¸íŠ¸ì—ë„ ë™ì¼ ì»·ì˜¤í”„ ì ìš©
            try:
                gas_dates_all = pd.to_datetime(data_processed.loc[X_gas.index, 'ë‚ ì§œ'], errors='coerce')
                cutoff = pd.Timestamp('2024-12-01')
                mask_after = gas_dates_all >= cutoff
                # ì¬ì ìš©
                X_gas_wd, y_gas_wd = X_gas_wd[mask_after.loc[X_gas_wd.index]], y_gas_wd[mask_after.loc[X_gas_wd.index]]
                X_gas_we, y_gas_we = X_gas_we[mask_after.loc[X_gas_we.index]], y_gas_we[mask_after.loc[X_gas_we.index]]
            except Exception:
                pass

            # ìµœì†Œ í‘œë³¸ í™•ì¸ í›„ ë¶„í• 
            if len(X_gas_wd) >= 20 and len(X_gas_we) >= 20:
                X_gas_wd_tr, X_gas_wd_te, y_gas_wd_tr, y_gas_wd_te = chronological_split(
                    X_gas_wd, y_gas_wd, data_processed.loc[X_gas_wd.index, 'ë‚ ì§œ'], test_size=test_size
                )
                X_gas_we_tr, X_gas_we_te, y_gas_we_tr, y_gas_we_te = chronological_split(
                    X_gas_we, y_gas_we, data_processed.loc[X_gas_we.index, 'ë‚ ì§œ'], test_size=test_size
                )

                st.session_state.X_gas_train_weekday = X_gas_wd_tr
                st.session_state.X_gas_test_weekday = X_gas_wd_te
                st.session_state.y_gas_train_weekday = y_gas_wd_tr
                st.session_state.y_gas_test_weekday = y_gas_wd_te

                st.session_state.X_gas_train_weekend = X_gas_we_tr
                st.session_state.X_gas_test_weekend = X_gas_we_te
                st.session_state.y_gas_train_weekend = y_gas_we_tr
                st.session_state.y_gas_test_weekend = y_gas_we_te
            else:
                st.warning("âš ï¸ í‰ì¼/ì£¼ë§ ë¶„ë¦¬ í•™ìŠµì„ ìœ„í•œ í‘œë³¸ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¨ì¼ ëª¨ë¸ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        except Exception:
                st.warning("âš ï¸ í‰ì¼/ì£¼ë§ ë¶„ë¦¬ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹¨ì¼ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("â„¹ï¸ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("---")

# --- 4. ëª¨ë¸ í•™ìŠµ (ë‹¨ì¼ ëª¨ë¸) ---
with st.expander("ğŸ¤– Step 4: ëª¨ë¸ í•™ìŠµ", expanded=False):
    # ì „ì—­ ë¡œë”© ì¼œê¸° (ìƒë‹¨ ë°°ë„ˆ í‘œì‹œ)
    if not st.session_state.get('is_training', False):
        st.session_state.is_training = True
        # ìƒë‹¨ ë°°ë„ˆ í‘œì‹œ
        with global_status_placeholder.container():
            st.info("â³ Step 4/5: ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€ ì§„í–‰ ì¤‘...")

    with st.spinner("ëª¨ë¸ì„ í•™ìŠµ ì¤‘..."):
        # NOTE: ì‹¤ì œ í•™ìŠµ ì½”ë“œëŠ” ì•„ë˜ì— ìˆìœ¼ë©°, êµ¬ë¬¸ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë³¸ ë¸”ë¡ì— ìµœì†Œ ë³¸ë¬¸ì„ ë‘¡ë‹ˆë‹¤.
        pass
    st.subheader("ğŸ“ˆ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ")
    # ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (ê°„ë‹¨ íŠœë‹ ì ìš©)
    try:
        rf_max = tune_rf_model(X_max_train, y_max_train, random_state=random_state)
    except Exception:
        rf_max = train_rf_model(X_max_train, y_max_train, n_estimators=n_estimators, random_state=random_state)
    
    # ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ (ë‹¨ì¼ ëª¨ë¸ë¡œ ê³ ì •)
    if hasattr(st.session_state, 'features_gas'):
        features_for_constraints = st.session_state.features_gas
        constraint_map = {
            'ìµœëŒ€ìˆ˜ìš”': 1,
            'íƒœì–‘ê´‘ìµœëŒ€': -1,
            'ì”ì—¬ë¶€í•˜': 1,
            'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨': -1,
            'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨': 1,
            'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°': 1,
            'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”': 0,
            'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨': 0,
            'í‰ì¼_í‰ì¼': 0,
        }
        monotone_constraints = [constraint_map.get(f, 0) for f in features_for_constraints]

        # ë‹¨ì¼ ëª¨ë¸ë¡œ í•™ìŠµ
        st.session_state.gas_model = train_lgbm_gas_model(
            st.session_state.X_gas_train,
            st.session_state.y_gas_train,
            monotone_constraints=monotone_constraints,
            n_estimators=300,
            learning_rate=0.05,
            num_leaves=63,
            min_child_samples=10,
            random_state=random_state,
        )
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ë° ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ë‹¨ì¼)")
    else:
        st.success("âœ… ì „ë ¥ìˆ˜ìš” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

st.markdown("---")

 # --- 5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---
with st.expander("ğŸ“Š Step 5: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€", expanded=False):
    with st.spinner("ì„±ëŠ¥ì„ í‰ê°€ ì¤‘..."):
        st.subheader("ğŸ“ˆ ë‹¨ì¼ ëª¨ë¸ ì„±ëŠ¥ (ê²€ì¦ ì„¸íŠ¸)")
        y_pred = rf_max.predict(X_max_test)
        st.session_state.mae_max = mean_absolute_error(y_max_test, y_pred)
        st.session_state.r2_max = r2_score(y_max_test, y_pred)
    
    # ê°€ìŠ¤ìˆ˜ìš” ë‹¨ì¼ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        if hasattr(st.session_state, 'gas_model') and hasattr(st.session_state, 'X_gas_test'):
            y_gas_pred = st.session_state.gas_model.predict(st.session_state.X_gas_test)
            st.session_state.mae_gas = mean_absolute_error(st.session_state.y_gas_test, y_gas_pred)
            st.session_state.r2_gas = r2_score(st.session_state.y_gas_test, y_gas_pred)

        # ì„±ëŠ¥ ê²°ê³¼ í‘œì‹œ (ìµœëŒ€ìˆ˜ìš” / ê°€ìŠ¤ìˆ˜ìš” ë‚˜ë€íˆ)
        if hasattr(st.session_state, 'mae_gas') and hasattr(st.session_state, 'r2_gas'):
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
                st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_max:,.0f} MW")
                st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_max:.4f}")
            with col2:
                st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
                st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_gas:,.0f} MW")
                st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_gas:.4f}")
        else:
            st.subheader("ğŸ“ˆ ìµœëŒ€ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥")
            st.metric("ê²€ì¦ MAE", f"{st.session_state.mae_max:,.0f} MW")
            st.metric("ê²€ì¦ RÂ²", f"{st.session_state.r2_max:.4f}")

    # ì „ì—­ ë¡œë”© ë„ê¸° ë° ìƒë‹¨ ë°°ë„ˆ ì œê±°
    if st.session_state.get('is_training', False):
        st.session_state.is_training = False
        global_status_placeholder.empty()

 

# ê·¸ë˜í”„ ë¹„í‘œì‹œ(ìš”ì²­ì— ë”°ë¼ ê²€ì¦ ë¼ì¸ì°¨íŠ¸ ìƒëµ)

st.markdown("---")

# --- 6. ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ---
st.header("ğŸ”® Step 6: ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡")

# ì˜ˆì¸¡ ì…ë ¥ í¼
col1, col2 = st.columns(2)

# ì˜ˆì¸¡ ì‹¤í–‰

# --- ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡ ---
st.markdown("---")
st.subheader("ğŸ“… ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡")
st.info(
    "ì„ íƒí•œ ë‚ ì§œì˜ ìš”ì¼Â·ê³µíœ´ì¼Â·ì—…ë¬´ì¼Â·ì›”(ì‹œì¦Œ)ì„ ë°˜ì˜í•˜ê³ , ë˜ê·¸ëŠ” ì–´ì œ(t-1), ì „ì£¼ ë™ì¼ ìš”ì¼(t-7), ì‘ë…„ ë™ì¼ ìš”ì¼(ì „ë…„ë„ ì›”Ã—ìš”ì¼ í‰ê· )ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. "
    "ì˜¨ë„ëŠ” ì‹œíŠ¸ ê°’ì´ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©, ì—†ìœ¼ë©´ ì…ë ¥ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì—¬ë¦„ì—” ìµœê³ ê¸°ì˜¨, ê²¨ìš¸ì—” ìµœì €ê¸°ì˜¨/ì²´ê°ì˜¨ë„ë¥¼ í™œìš©í•´ ëƒ‰ë°©/ë‚œë°© ê°•ë„ë¥¼ ê³„ì‚°í•˜ë©°, "
    "ìš”ì¼ì€ ì›-í•«, ì—…ë¬´ì¼ì€ ê³µíœ´ì¼ì„ ê³ ë ¤í•œ í‰ì¼ í”Œë˜ê·¸ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤."
)

with st.form("date_based_forecast_form"):
    # ê¸°ë³¸ ë‚ ì§œ: ë°ì´í„° ë§ˆì§€ë§‰ ë‚ ì§œ ë‹¤ìŒë‚ , ì—†ìœ¼ë©´ ì˜¤ëŠ˜
    try:
        latest_ts = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce').dropna().max()
        default_target_date = (latest_ts + pd.Timedelta(days=1)).date()
    except Exception:
        default_target_date = pd.Timestamp.today().date()

    target_date = st.date_input("ì˜ˆì¸¡ ë‚ ì§œ ì„ íƒ", value=default_target_date, key="target_date_input")

    # ì˜¨ë„ ì…ë ¥(ì‹œíŠ¸ì— ì—†ì„ ê²½ìš° ì‚¬ìš©)
    colA, colB, colC = st.columns(3)
    with colA:
        min_temp_input = st.number_input("ìµœì €ê¸°ì˜¨ (Â°C) [ì˜µì…˜]", min_value=-50.0, max_value=50.0, value=0.0, step=0.1, key="date_min_temp")
    with colB:
        max_temp_input = st.number_input("ìµœê³ ê¸°ì˜¨ (Â°C) [ì˜µì…˜]", min_value=-50.0, max_value=50.0, value=0.0, step=0.1, key="date_max_temp")
    with colC:
        feels_like_input = st.number_input("ì²´ê°ì˜¨ë„ (Â°C) [ì˜µì…˜]", min_value=-50.0, max_value=50.0, value=0.0, step=0.1, key="date_feels_like")

    submit_date_forecast = st.form_submit_button("ğŸ”® ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡ ì‹¤í–‰")

if submit_date_forecast:
    try:
        with st.spinner("ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰ ì¤‘..."):
            target_ts = pd.to_datetime(target_date)
            weekday_map = {0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'}
            weekday_name = weekday_map.get(int(target_ts.weekday()))
            month_val = int(target_ts.month)

            # ì‹œì¦Œ íŒë³„
            is_summer = month_val in [5, 6, 7, 8, 9]
            is_winter = month_val in [10, 11, 12, 1, 2, 3, 4]

            # ì‹œíŠ¸ ê¸°ë°˜ ì˜¨ë„ê°’ ì¡°íšŒ(ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
            min_temp_val = None
            max_temp_val = None
            feels_like_val = None
            try:
                if 'ë‚ ì§œ' in data.columns:
                    df_sorted = data.copy()
                    df_sorted['ë‚ ì§œ'] = pd.to_datetime(df_sorted['ë‚ ì§œ'], errors='coerce')
                    row_today = df_sorted[df_sorted['ë‚ ì§œ'].dt.date == target_ts.date()]
                    if not row_today.empty:
                        if 'ìµœì €ê¸°ì˜¨' in row_today.columns:
                            min_temp_val = pd.to_numeric(row_today['ìµœì €ê¸°ì˜¨'], errors='coerce').iloc[0]
                        if 'ìµœê³ ê¸°ì˜¨' in row_today.columns:
                            max_temp_val = pd.to_numeric(row_today['ìµœê³ ê¸°ì˜¨'], errors='coerce').iloc[0]
                        if 'ì²´ê°ì˜¨ë„' in row_today.columns:
                            feels_like_val = pd.to_numeric(row_today['ì²´ê°ì˜¨ë„'], errors='coerce').iloc[0]
            except Exception:
                pass

            # ì…ë ¥ê°’ìœ¼ë¡œ ë³´ì™„
            if pd.isna(min_temp_val) if min_temp_val is not None else True:
                min_temp_val = None if not is_winter else float(min_temp_input)
            if pd.isna(max_temp_val) if max_temp_val is not None else True:
                max_temp_val = None if not is_summer else float(max_temp_input)
            if pd.isna(feels_like_val) if feels_like_val is not None else True:
                feels_like_val = float(feels_like_input) if feels_like_input is not None else None
            if feels_like_val is None:
                # ëŒ€ìš©: ì—¬ë¦„ì—” ìµœê³ ê¸°ì˜¨, ê²¨ìš¸ì—” ìµœì €ê¸°ì˜¨, ì´ì™¸ í‰ê·  ëŒ€ìš©
                if is_summer and max_temp_val is not None:
                    feels_like_val = float(max_temp_val)
                elif is_winter and min_temp_val is not None:
                    feels_like_val = float(min_temp_val)
                else:
                    feels_like_val = float((min_temp_val or 0.0 + max_temp_val or 0.0) / 2.0)

            # ê³µíœ´ì¼/ì—…ë¬´ì¼/í‰ì¼ í”Œë˜ê·¸ ì‚°ì¶œ (í•œêµ­ ê³µíœ´ì¼ ê¸°ì¤€)
            try:
                kr_holidays = holidays.KR()
            except Exception:
                kr_holidays = {}
            weekday_num = int(target_ts.weekday())
            is_holiday_flag = 1 if target_ts.date() in kr_holidays else 0
            is_business_day_flag = 1 if (weekday_num < 5 and is_holiday_flag == 0) else 0
            # ê¸°ì¡´ ì‹œíŠ¸ì˜ 'í‰ì¼' ê°’ì´ ìˆë‹¤ë©´ ë³´ì •(ë‹¨, ê³µíœ´ì¼ì´ë©´ ìš°ì„ ì ìœ¼ë¡œ íœ´ì¼ ì²˜ë¦¬)
            try:
                if 'í‰ì¼' in data.columns:
                    row_today = data[pd.to_datetime(data['ë‚ ì§œ'], errors='coerce').dt.date == target_ts.date()]
                    if not row_today.empty:
                        sheet_weekday = 1 if str(row_today['í‰ì¼'].iloc[0]) == 'í‰ì¼' else 0
                        if is_holiday_flag == 1:
                            is_business_day_flag = 0
                        else:
                            is_business_day_flag = sheet_weekday
            except Exception:
                pass
            # ëª¨ë¸ ì…ë ¥ìš© ë‹¨ìˆœ í”Œë˜ê·¸ (í‰ì¼_í‰ì¼ ì œê±°ì— ë”°ë¼ ë”ë¯¸ì—ì„œë§Œ ì‚¬ìš©)
            is_weekday_flag = is_business_day_flag

            # ë˜ê·¸ ê³„ì‚°: ê³¼ê±° ê´€ì¸¡ì—ì„œ ì¶”ì¶œ
            y_series = None
            try:
                dfp = data_processed.copy()
                dfp['ë‚ ì§œ'] = pd.to_datetime(dfp['ë‚ ì§œ'], errors='coerce')
                dfp = dfp.sort_values('ë‚ ì§œ')
                past = dfp[dfp['ë‚ ì§œ'] < target_ts]
                y_series = pd.to_numeric(past['ìµœëŒ€ìˆ˜ìš”'], errors='coerce').dropna()
            except Exception:
                y_series = pd.Series(dtype=float)

            # ì–´ì œ(t-1)

            # 7ì¼ í‰ê·  ì œê±° ìš”ì²­ìœ¼ë¡œ ë¯¸ì‚¬ìš©

            # ì „ì£¼ ë™ì¼ ìš”ì¼(t-7)
            try:
                y_t7 = 0.0
                exact_t7 = dfp[dfp['ë‚ ì§œ'] == (target_ts - pd.Timedelta(days=7))]
                if not exact_t7.empty:
                    y_t7 = float(pd.to_numeric(exact_t7['ìµœëŒ€ìˆ˜ìš”'], errors='coerce').iloc[0])
                elif len(y_series) >= 7:
                    y_t7 = float(y_series.iloc[-7])
            except Exception:
                y_t7 = 0.0

            # ì‘ë…„ ë™ì¼ì¼
            try:
                ly_map = st.session_state.get('last_year_month_weekday_mean_max', {})
                wd_name = weekday_name
                ly_val = float(ly_map.get((month_val, wd_name), 0.0)) if ly_map else 0.0
            except Exception:
                ly_val = 0.0

            # í”¼ì²˜ êµ¬ì„±
            feature_row = {
                'ëƒ‰ë°©ê°•ë„': max(0.0, (feels_like_val if max_temp_val is None else max_temp_val) - 25.0),
                'ë‚œë°©ê°•ë„': max(0.0, 10.0 - (min_temp_val if min_temp_val is not None else feels_like_val)),
                'ì›”': month_val,
                'ì–´ì œì˜_ìµœëŒ€ìˆ˜ìš”': float(y_series.iloc[-1]) if 'y_series' in locals() and len(y_series) > 0 else 0.0,
                'ì „ì£¼ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”': y_t7,
                'ì‘ë…„ë™ì¼ìš”ì¼_ìµœëŒ€ìˆ˜ìš”': ly_val,
                'ê³µíœ´ì¼': int(is_holiday_flag),
                'ì—…ë¬´ì¼': int(is_business_day_flag),
                'ìµœê³ ê¸°ì˜¨': (max_temp_val if max_temp_val is not None else feels_like_val) if is_summer else 0.0,
                'ìµœì €ê¸°ì˜¨': (min_temp_val if min_temp_val is not None else feels_like_val) if is_winter else 0.0,
                'ì²´ê°ì˜¨ë„': feels_like_val,
                'ì¼êµì°¨': ( (max_temp_val - min_temp_val) if (max_temp_val is not None and min_temp_val is not None) else 0.0 ),
            }
            feature_row.update({f'ìš”ì¼_{w}': (1 if w == weekday_name else 0) for w in ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼']})

            model_for_date = rf_max
            frame = pd.DataFrame([feature_row])
            frame = align_features_for_model(model_for_date, frame)
            predicted_by_date = float(model_for_date.predict(frame)[0])

            st.success("âœ… ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ!")
            st.metric("ì˜ˆì¸¡ ìµœëŒ€ìˆ˜ìš”", f"{predicted_by_date:,.0f} MW")

            # ê¸°ì¤€ ëŒ€ë¹„ ë³€í™”ëŸ‰: ì „ì£¼ ë™ì¼ ìš”ì¼ ëŒ€ë¹„ë¡œ ë³€ê²½
            try:
                base_val = y_t7
                delta = predicted_by_date - base_val
                st.metric("ì „ì£¼ ë™ì¼ ìš”ì¼ ëŒ€ë¹„", f"{delta:,.0f} MW", delta=delta)
            except Exception:
                pass

            # ì‘ë…„ ë™ì¼ ì£¼ ìš”ì¼ë³„ ìµœëŒ€ìˆ˜ìš”(2/29ëŠ” 2/28ë¡œ ëŒ€ì²´) í‘œì‹œ
            try:
                prev_year = int(target_ts.year) - 1
                try:
                    anchor = target_ts.replace(year=prev_year)
                except Exception:
                    if int(target_ts.month) == 2 and int(target_ts.day) == 29:
                        anchor = pd.Timestamp(year=prev_year, month=2, day=28)
                    else:
                        anchor = target_ts - pd.Timedelta(days=365)

                week_start = anchor - pd.Timedelta(days=int(anchor.weekday()))
                week_dates = [week_start + pd.Timedelta(days=i) for i in range(7)]

                df_lookup = data.copy()
                df_lookup['ë‚ ì§œ'] = pd.to_datetime(df_lookup['ë‚ ì§œ'], errors='coerce')
                weekday_map_disp = {0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'}

                rows = []
                for dti in week_dates:
                    mask = df_lookup['ë‚ ì§œ'].dt.date == dti.date()
                    if mask.any() and 'ìµœëŒ€ìˆ˜ìš”' in df_lookup.columns:
                        val = pd.to_numeric(df_lookup.loc[mask, 'ìµœëŒ€ìˆ˜ìš”'], errors='coerce').iloc[0]
                    else:
                        val = np.nan
                    rows.append({
                        'ìš”ì¼': weekday_map_disp[int(dti.weekday())],
                        'ë‚ ì§œ': dti.strftime('%Y-%m-%d'),
                        'ìµœëŒ€ìˆ˜ìš”': val,
                    })

                df_same_week = pd.DataFrame(rows)
                st.subheader("ğŸ“… ì‘ë…„ ë™ì¼ ì£¼ ìš”ì¼ë³„ ìµœëŒ€ìˆ˜ìš”")
                st.dataframe(df_same_week, use_container_width=True)
            except Exception:
                pass

    except Exception as e:
        st.error(f"âŒ ë‚ ì§œ ê¸°ë°˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# --- ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì„¹ì…˜ ---
st.markdown("---")
st.subheader("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡")
st.info("ìµœëŒ€ìˆ˜ìš”ì™€ íƒœì–‘ê´‘ìµœëŒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ìŠ¤ìˆ˜ìš”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
if hasattr(st.session_state, 'gas_model'):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì¡°ê±´ ì…ë ¥")
        
        # ìš”ì¼ ì„ íƒ + í•œêµ­ ê³µíœ´ì¼/ì—…ë¬´ì¼ íŒì •
        gas_weekday = st.selectbox("ìš”ì¼ ì„ íƒ", ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'], index=0, key="gas_weekday")
        gas_date_for_flag = st.date_input("ì˜ˆì¸¡ ê¸°ì¤€ ë‚ ì§œ(ì—…ë¬´ì¼/ê³µíœ´ì¼ íŒì •)", value=pd.Timestamp.today().date(), key="gas_date_flag")
        try:
            kr_holidays = holidays.KR()
        except Exception:
            kr_holidays = {}
        gas_is_holiday = 1 if gas_date_for_flag in kr_holidays else 0
        gas_weekday_num = ['ì›”ìš”ì¼','í™”ìš”ì¼','ìˆ˜ìš”ì¼','ëª©ìš”ì¼','ê¸ˆìš”ì¼','í† ìš”ì¼','ì¼ìš”ì¼'].index(gas_weekday)
        gas_is_business = 1 if (gas_weekday_num < 5 and gas_is_holiday == 0) else 0

        # ìµœëŒ€ìˆ˜ìš” ì…ë ¥
        max_demand_input = st.number_input(
            "ìµœëŒ€ìˆ˜ìš” (MW)",
            min_value=0.0,
            max_value=100000.0,
            value=50000.0,
            step=1000.0
        )
        
        # íƒœì–‘ê´‘ìµœëŒ€ ì…ë ¥
        solar_max_input = st.number_input(
            "íƒœì–‘ê´‘ìµœëŒ€ (MW)",
            min_value=0.0,
            max_value=100000.0,
            value=50000.0,
            step=1000.0
        )
        
        # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ë²„íŠ¼
        predict_gas_button = st.button("ğŸ”¥ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡", type="primary")
    
    with col2:
        st.subheader("ğŸ“Š ê°€ìŠ¤ìˆ˜ìš” ì…ë ¥ ì •ë³´")
        st.write(f"**ìš”ì¼:** {gas_weekday}")
        st.write(f"**ê³µíœ´ì¼:** {'ì˜ˆ' if gas_is_holiday else 'ì•„ë‹ˆì˜¤'}")
        st.write(f"**ì—…ë¬´ì¼:** {'ì˜ˆ' if gas_is_business else 'ì•„ë‹ˆì˜¤'}")
        st.write(f"**ìµœëŒ€ìˆ˜ìš”:** {max_demand_input:,.0f} MW")
        st.write(f"**íƒœì–‘ê´‘ìµœëŒ€:** {solar_max_input:,.0f} MW")
    
    # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì‹¤í–‰
    if predict_gas_button:
        try:
            with st.spinner("ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìˆ˜í–‰ ì¤‘..."):
                # ì˜ˆì¸¡ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŠ¹ì§•ê³¼ ì •í•©)
                last_gas = st.session_state.get('last_gas', None)
                prev_gas = st.session_state.get('prev_gas', None)

                # ë³€í™”ìœ¨ ê³„ì‚° (ê°€ëŠ¥í•˜ë©´), ë¶ˆê°€ ì‹œ 0.0
                if last_gas is not None and prev_gas is not None and prev_gas != 0:
                    gas_rate = (last_gas - prev_gas) / prev_gas
                else:
                    gas_rate = 0.0

                # ì…ë ¥ ê¸°ë°˜ íŒŒìƒ
                residual_load_input = max_demand_input - solar_max_input
                denom_total = max_demand_input if max_demand_input != 0 else 1.0
                solar_ratio_total = solar_max_input / denom_total
                residual_ratio_total = residual_load_input / denom_total

                # ì•ˆì „í•œ ê°€ìŠ¤/íƒœì–‘ê´‘ ë¹„ìœ¨ (ìµœê·¼ ê°€ìŠ¤ê°€ ì—†ë‹¤ë©´ 0)
                # í•„ìš” ì—†ëŠ” íŒŒìƒ ì œê±°: íƒœì–‘ê´‘_ê°€ìŠ¤_ë¹„ìœ¨ ì‚¬ìš© ì•ˆ í•¨

                # ì˜ˆì¸¡ ì…ë ¥ì„ í•™ìŠµ íŠ¹ì§•ì— ë§ì¶° êµ¬ì„± (ëˆ„ë½ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›€)
                input_dict = {f: 0.0 for f in st.session_state.features_gas}
                input_dict.update({
                    'ìµœëŒ€ìˆ˜ìš”': max_demand_input,
                    'íƒœì–‘ê´‘ìµœëŒ€': solar_max_input,
                    'ì”ì—¬ë¶€í•˜': residual_load_input,
                    'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_íƒœì–‘ê´‘ë¹„ìœ¨': solar_ratio_total,
                    'ìµœëŒ€ìˆ˜ìš”ëŒ€ë¹„_ì”ì—¬ë¶€í•˜ë¹„ìœ¨': residual_ratio_total,
                    'ëª©í‘œê°€ìŠ¤_ì˜ˆì‚°': max_demand_input * (st.session_state.get('gas_total_ratio_weekday', 0.0) if gas_is_business else st.session_state.get('gas_total_ratio_weekend', 0.0)) - solar_max_input,
                    'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”': last_gas if last_gas is not None else 0.0,
                    'ì–´ì œì˜_ê°€ìŠ¤ìˆ˜ìš”_ë³€í™”ìœ¨': gas_rate,
                    'ì—…ë¬´ì¼': float(gas_is_business),
                    'ê³µíœ´ì¼': float(gas_is_holiday),
                })

                prediction_input_gas = pd.DataFrame([input_dict])
                
                # Step 5ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì˜ íŠ¹ì§• ë³€ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤
                if hasattr(st.session_state, 'features_gas'):
                    prediction_input_gas = prediction_input_gas[st.session_state.features_gas]
                    
                    # ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ (ë‹¨ì¼ ëª¨ë¸)
                    predicted_gas_demand = st.session_state.gas_model.predict(prediction_input_gas)[0]
                    # ë¬¼ë¦¬ì  í´ë¦¬í•‘: 0 â‰¤ ê°€ìŠ¤ â‰¤ ìµœëŒ€ìˆ˜ìš”
                    predicted_gas_demand = max(0.0, min(predicted_gas_demand, max_demand_input))
                    
                    st.success("âœ… ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì™„ë£Œ!")
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
                    st.subheader("ğŸ“Š ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì…ë ¥ ìµœëŒ€ìˆ˜ìš”", f"{max_demand_input:,.0f} MW")
                    with col2:
                        st.metric("ì…ë ¥ íƒœì–‘ê´‘ìµœëŒ€", f"{solar_max_input:,.0f} MW")
                    with col3:
                        st.metric("ì˜ˆì¸¡ ê°€ìŠ¤ìˆ˜ìš”", f"{predicted_gas_demand:,.0f} MW")
                    
                    # ì˜ˆì¸¡ ì‹ ë¢°ë„
                    confidence_gas = min(95, max(60, st.session_state.r2_gas * 100)) if hasattr(st.session_state, 'r2_gas') else 60
                    st.metric("ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{confidence_gas:.1f}%")
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
                    st.subheader("ğŸ“ˆ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì‹œê°í™”")
                    
                    fig_prediction_gas = go.Figure()
                    
                    fig_prediction_gas.add_trace(go.Bar(
                        x=['ìµœëŒ€ìˆ˜ìš”', 'íƒœì–‘ê´‘ìµœëŒ€', 'ì˜ˆì¸¡ ê°€ìŠ¤ìˆ˜ìš”'],
                        y=[max_demand_input, solar_max_input, predicted_gas_demand],
                        name='ì…ë ¥ê°’ ë° ì˜ˆì¸¡ê°’',
                        marker_color=['red', 'orange', 'green']
                    ))
                    
                    fig_prediction_gas.update_layout(
                        title="ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼",
                        yaxis_title="ê°’ (MW)",
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_prediction_gas, use_container_width=True)
                    
                    # ì˜ˆì¸¡ ê·¼ê±° ì„¤ëª…
                    st.subheader("ğŸ“‹ ì˜ˆì¸¡ ê·¼ê±°")
                    # ëª¨ë¸ ì¤‘ìš”ë„
                    feature_importance = st.session_state.gas_model.feature_importances_
                    
                    # Step 5ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì˜ ì‹¤ì œ íŠ¹ì§• ë³€ìˆ˜ ì‚¬ìš©
                    if hasattr(st.session_state, 'features_gas'):
                        if feature_importance is not None:
                            importance_df = pd.DataFrame({
                                'íŠ¹ì„±': st.session_state.features_gas,
                                'ì¤‘ìš”ë„': feature_importance
                            }).sort_values('ì¤‘ìš”ë„', ascending=False)
                            st.info(f"ğŸ’¡ ì£¼ìš” ì˜í–¥ ìš”ì¸: {importance_df.iloc[0]['íŠ¹ì„±']} ({importance_df.iloc[0]['ì¤‘ìš”ë„']:.1%})")
                            if len(importance_df) > 1:
                                st.info(f"ğŸ’¡ ë³´ì¡° ì˜í–¥ ìš”ì¸: {importance_df.iloc[1]['íŠ¹ì„±']} ({importance_df.iloc[1]['ì¤‘ìš”ë„']:.1%})")
                    else:
                        st.info("ğŸ’¡ ëª¨ë¸ì˜ íŠ¹ì§• ì¤‘ìš”ë„ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                else:
                    st.error("âŒ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            st.error(f"âŒ ê°€ìŠ¤ìˆ˜ìš” ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ê°€ìŠ¤ìˆ˜ìš” ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì…ë ¥ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown("---")

# --- 7. ê´€ë ¨ ë§í¬ ---
st.header("ğŸ”— ê´€ë ¨ ë§í¬")
st.info("ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ê²€ì¦ì— ì‚¬ìš©ìˆ˜ ìˆëŠ” ë°ì´í„° ì†ŒìŠ¤ì…ë‹ˆë‹¤.")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸŒ¤ï¸ ê¸°ìƒì²­ ê¸°ìƒìë£Œê°œë°©í¬í„¸")
    st.write("ê¸°ì˜¨, ìŠµë„ ë“± ê¸°ìƒ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    st.markdown(
        "[ê¸°ìƒì²­ ê¸°ìƒìë£Œê°œë°©í¬í„¸ ë°”ë¡œê°€ê¸°](https://data.kma.go.kr/stcs/grnd/grndTaList.do?pgmNo=70)",
        help="ê¸°ìƒì²­ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ìƒ ê´€ì¸¡ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

with col2:
    st.subheader("âš¡ í•œêµ­ì „ë ¥ê±°ë˜ì†Œ")
    st.write("ì‹¤ì‹œê°„ ì „ë ¥ ìˆ˜ìš” ë° ê³µê¸‰ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.markdown(
        "[í•œêµ­ì „ë ¥ê±°ë˜ì†Œ ë°”ë¡œê°€ê¸°](https://www.kpx.or.kr/powerinfoSubmain.es?mid=a10606030000)",
        help="í•œêµ­ì „ë ¥ê±°ë˜ì†Œì—ì„œ ì œê³µí•˜ëŠ” ì „ë ¥ ìˆ˜ìš” ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

st.markdown("---")
